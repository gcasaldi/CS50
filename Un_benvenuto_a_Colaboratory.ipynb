{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcasaldi/CS50/blob/main/Un_benvenuto_a_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxjvmwmCz0_A",
        "outputId": "a613999e-6132-443e-beba-f2eb83886af0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Carica il file ZIP\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verifica il nome del file caricato\n",
        "file_name = list(uploaded.keys())[0]\n",
        "zip_path = f'/content/{file_name}'\n",
        "\n",
        "# Estrai il contenuto del file ZIP\n",
        "extracted_folder = '/content/extracted/'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "# Verifica i file estratti\n",
        "extracted_files = os.listdir(extracted_folder)\n",
        "print(f\"File estratti: {extracted_files}\")\n",
        "\n",
        "# Salva il path del file Excel estratto per usarlo nella seconda cella\n",
        "excel_file_path = os.path.join(extracted_folder, extracted_files[0])\n",
        "print(f\"File Excel estratto: {excel_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ste5YD1_IghP",
        "outputId": "6bbaa688-ff82-412d-e0f4-6442d9b4d3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3af93a4e-eb70-48f9-aa0a-a1e0368673a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3af93a4e-eb70-48f9-aa0a-a1e0368673a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving it-superenalotto-past-draws-archive.zip to it-superenalotto-past-draws-archive.zip\n",
            "File estratti: ['it-superenalotto-past-draws-archive.xls']\n",
            "File Excel estratto: /content/extracted/it-superenalotto-past-draws-archive.xls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Usa il path ottenuto dalla prima cella\n",
        "file_path = '/content/extracted/it-superenalotto-past-draws-archive.xls'  # Assicurati che questo percorso sia corretto\n",
        "\n",
        "def carica_database(file_path):\n",
        "    # Usa 'xlrd' come engine per i file .xls\n",
        "    df = pd.read_excel(file_path, engine='xlrd', skiprows=1)\n",
        "    numeri_estratti = df.select_dtypes(include='number').dropna(axis=1, how='all')\n",
        "    numeri_estratti = numeri_estratti.tail(500)\n",
        "    return numeri_estratti\n",
        "\n",
        "# Carica i dati nel DataFrame\n",
        "df = carica_database(file_path)\n",
        "\n",
        "# Visualizza le prime 10 righe\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sia9c1rtLRf5",
        "outputId": "1ae6a08f-0732-48e0-be9d-186fcc120325"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
            "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
            "0         NaN         NaN         NaN         NaN         NaN\n",
            "1         NaN         NaN         NaN         NaN         NaN\n",
            "2         2.0         3.0         4.0         5.0         6.0\n",
            "3        16.0        35.0        59.0        65.0        87.0\n",
            "4        24.0        25.0        30.0        43.0        47.0\n",
            "5        10.0        18.0        19.0        32.0        36.0\n",
            "6        28.0        52.0        63.0        77.0        79.0\n",
            "7        12.0        33.0        40.0        41.0        83.0\n",
            "8        12.0        37.0        59.0        63.0        90.0\n",
            "9        31.0        33.0        42.0        51.0        72.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codice per ordinare e correggere i dati:"
      ],
      "metadata": {
        "id": "NMlAQ3KPZJCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulizia dei dati: rimuoviamo le colonne vuote e manteniamo solo i numeri\n",
        "def pulizia_dati(df):\n",
        "    df_cleaned = df.select_dtypes(include='number').dropna(axis=1, how='all')  # Manteniamo solo colonne con numeri\n",
        "    return df_cleaned\n",
        "\n",
        "# Applichiamo la pulizia\n",
        "df_cleaned = pulizia_dati(df)\n",
        "\n",
        "# Mostra le prime 10 righe dopo la pulizia\n",
        "print(df_cleaned.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxPxAV8QMQ-R",
        "outputId": "10e14dc3-3add-4ae2-978a-a150eb305bd9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
            "0         NaN         NaN         NaN         NaN         NaN\n",
            "1         NaN         NaN         NaN         NaN         NaN\n",
            "2         2.0         3.0         4.0         5.0         6.0\n",
            "3        16.0        35.0        59.0        65.0        87.0\n",
            "4        24.0        25.0        30.0        43.0        47.0\n",
            "5        10.0        18.0        19.0        32.0        36.0\n",
            "6        28.0        52.0        63.0        77.0        79.0\n",
            "7        12.0        33.0        40.0        41.0        83.0\n",
            "8        12.0        37.0        59.0        63.0        90.0\n",
            "9        31.0        33.0        42.0        51.0        72.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j1VxXlRJTKfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleziona solo le colonne numeriche (i numeri estratti)"
      ],
      "metadata": {
        "id": "u9YJhjwgQaKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleziona solo le colonne numeriche (i numeri estratti)\n",
        "df_cleaned = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Rimuove righe che contengono tutti valori NaN\n",
        "df_cleaned = df_cleaned.dropna(how='all')\n",
        "\n",
        "# Converte i numeri in interi per eliminare i .0\n",
        "df_cleaned = df_cleaned.astype(int)\n",
        "\n",
        "# Stampa i primi numeri per verificare\n",
        "print(df_cleaned.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0IdgeqrQdWw",
        "outputId": "9f5f67bc-5f48-4cb9-f952-422a1634aef6"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
            "2            2           3           4           5           6\n",
            "3           16          35          59          65          87\n",
            "4           24          25          30          43          47\n",
            "5           10          18          19          32          36\n",
            "6           28          52          63          77          79\n",
            "7           12          33          40          41          83\n",
            "8           12          37          59          63          90\n",
            "9           31          33          42          51          72\n",
            "10          58          68          83          89          90\n",
            "11          40          48          49          52          89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Prendi solo le ultime 500 estrazioni"
      ],
      "metadata": {
        "id": "u8ej44cHQf5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df_cleaned.tail(800)"
      ],
      "metadata": {
        "id": "PpUAkVMoQidR"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizza i dati tra 0 e 1"
      ],
      "metadata": {
        "id": "7RBwT-sAQlOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df_scaled = scaler.fit_transform(df_cleaned)\n"
      ],
      "metadata": {
        "id": "1CxlovdwQnkI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Funzione per creare sequenze di dati"
      ],
      "metadata": {
        "id": "qIcfZ0ahQqEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepara_dati(df_scaled, sequenza_lunghezza=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df_scaled) - sequenza_lunghezza):\n",
        "        X.append(df_scaled[i:i + sequenza_lunghezza])\n",
        "        y.append(df_scaled[i + sequenza_lunghezza])  # Previsione successiva\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "qUGFetRWQshw"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepara i dati per il modello LSTM"
      ],
      "metadata": {
        "id": "lo11sdSHQxhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepara_dati(df_scaled, sequenza_lunghezza=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df_scaled) - sequenza_lunghezza):  # Modifica qui\n",
        "        X.append(df_scaled[i:i + sequenza_lunghezza])  # Aggiungi sequenza di lunghezza 5\n",
        "        y.append(df_scaled[i + sequenza_lunghezza])  # Previsione successiva\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "rpyJ3pyiQyzr"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo il modello LSTM e lo alleniamo"
      ],
      "metadata": {
        "id": "jn9uXI9hQ2gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepara i dati\n",
        "X, y = prepara_dati(df_scaled)\n",
        "\n",
        "# Dividi i dati in set di training e testing\n",
        "split_index = int(len(X) * 0.8)  # Usa l'80% per il training\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Crea il modello LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=y_train.shape[1]))  # Output layer con numero di unità pari a features\n",
        "\n",
        "# Compila il modello\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Allena il modello\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)  #epochs=50, batch_size=32\n",
        "\n",
        "# Valuta il modello\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss sul set di test: {loss}\")\n",
        "\n",
        "# Fai delle previsioni\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverti la normalizzazione per ottenere le previsioni nella scala originale\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "\n",
        "# Stampa le prime 10 previsioni\n",
        "print(\"Prime 10 previsioni:\")\n",
        "print(predictions[:10])\n",
        "\n",
        "# Stampa le prime 10 osservazioni reali\n",
        "print(\"\\nPrime 10 osservazioni reali:\")\n",
        "print(y_test[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UNX6AoNeB0z",
        "outputId": "9f97fffc-b6d1-422d-e77f-d4b29a0a16f8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.4807\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4516\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4218\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3953\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3680\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3451\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3193\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2940\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2633\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2390\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2281\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1894\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1677\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1382\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1136\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0992\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0898\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0681\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0700\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0802\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0827\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0779\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0843\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0868\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0697\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0668\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0731\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0698\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0600\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0785\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0583\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0582\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0589\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0667\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0577\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0660\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0663\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0609\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0633\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0677\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0575\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0626\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0582\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0562\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0580\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0617\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0608\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0583\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0648\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0577\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0582\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0572\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0532\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0579\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0543\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0590\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0583\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0528\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0511\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0605\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0601\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0571\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0473\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0605\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0589\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0615\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0642\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0636\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0422\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0512\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0470\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0684\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0572\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0548\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0587\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0631\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0565\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0628\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0566\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0498\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0544\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0617\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0531\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0579\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0643\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0522\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0462\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0571\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0500\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0479\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0602\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0512\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0433\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0543\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0547\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0512\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0592\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0577\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - loss: 0.0443\n",
            "Loss sul set di test: 0.044313836842775345\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "Prime 10 previsioni:\n",
            "[[27.233118 38.502842 54.945553 61.17108  76.00749 ]\n",
            " [26.930758 37.98834  54.169174 60.46741  74.58042 ]\n",
            " [27.722692 39.028976 55.790695 62.672565 77.085304]\n",
            " [27.148346 38.621914 55.72934  62.79154  77.502556]\n",
            " [26.579315 36.97986  53.237617 59.694862 73.28127 ]\n",
            " [26.725012 37.48579  54.510834 61.19739  75.286674]\n",
            " [27.453188 39.418995 57.27091  64.317764 79.645035]]\n",
            "\n",
            "Prime 10 osservazioni reali:\n",
            "[[ 6. 11. 22. 35. 85.]\n",
            " [25. 33. 49. 57. 72.]\n",
            " [33. 40. 71. 74. 82.]\n",
            " [10. 11. 29. 32. 87.]\n",
            " [42. 43. 63. 83. 86.]\n",
            " [30. 43. 49. 74. 89.]\n",
            " [21. 29. 74. 77. 88.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ottimizzazione del modello mix tra dati statistici e training"
      ],
      "metadata": {
        "id": "Qd14gmUAfddP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Funzione per calcolare la similarità tra la previsione e l'estrazione\n",
        "def calcola_similarita(previsione, estrazione):\n",
        "    return len(set(previsione) & set(estrazione))\n",
        "\n",
        "# Funzione per testare diverse combinazioni di pesi\n",
        "def ottimizza_pesi(previsione_ml, top_frequenti, ritardatari, estrazioni_reali):\n",
        "    best_weight_model = 0\n",
        "    best_weight_stat = 0\n",
        "    best_precision = 0\n",
        "\n",
        "    # Prova diverse combinazioni di pesi (grid search)\n",
        "    for weight_model in np.arange(0, 1.1, 0.1):\n",
        "        for weight_stat in np.arange(0, 1.1, 0.1):\n",
        "            if weight_model + weight_stat > 1:  # La somma dei pesi non deve superare 1\n",
        "                continue\n",
        "\n",
        "            previsione_combinata = []\n",
        "\n",
        "            # Aggiungi le previsioni del modello ponderate\n",
        "            for num in previsione_ml:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Aggiungi i numeri frequenti ponderati\n",
        "            for num in top_frequenti:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Aggiungi i numeri ritardatari ponderati\n",
        "            for num in ritardatari[:3]:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Se non raggiungi 6 numeri, aggiungi casualmente\n",
        "            while len(previsione_combinata) < 6:\n",
        "                random_number = np.random.choice(ritardatari)  # Aggiungi un numero ritardatario casuale\n",
        "                if random_number not in previsione_combinata:\n",
        "                    previsione_combinata.append(random_number)\n",
        "\n",
        "            # Calcola la similarità tra la previsione e le estrazioni reali\n",
        "            total_similarity = 0\n",
        "            for estrazione in estrazioni_reali:\n",
        "                total_similarity += calcola_similarita(previsione_combinata, estrazione)\n",
        "\n",
        "            # Calcola la precisione media\n",
        "            precisione = total_similarity / len(estrazioni_reali)\n",
        "\n",
        "            # Aggiorna la miglior combinazione di pesi\n",
        "            if precisione > best_precision:\n",
        "                best_precision = precisione\n",
        "                best_weight_model = weight_model\n",
        "                best_weight_stat = weight_stat\n",
        "\n",
        "    return best_weight_model, best_weight_stat, best_precision\n",
        "\n",
        "\n",
        "# Test su un sottoinsieme di estrazioni reali (ultime 50 estrazioni)\n",
        "estrazioni_reali = df.tail(50).values.tolist()  # Usa le ultime 50 estrazioni\n",
        "\n",
        "# Ottimizzazione dei pesi\n",
        "best_weight_model, best_weight_stat, best_precision = ottimizza_pesi(\n",
        "    predictions[-1].astype(int),  # Predizioni del modello\n",
        "    [num for num, freq in numeri_ordinati_frequenza[:5]],  # Top 5 numeri frequenti\n",
        "    ritardatari,  # Numeri ritardatari\n",
        "    estrazioni_reali\n",
        ")\n",
        "\n",
        "print(f\"\\nMigliori pesi trovati: modello={best_weight_model}, statistica={best_weight_stat}\")\n",
        "print(f\"Precisione media ottenuta: {best_precision:.2f}\")\n",
        "\n",
        "# Previsione finale con i pesi ottimizzati\n",
        "previsione_combinata_ottimizzata = []\n",
        "\n",
        "# Aggiungi le previsioni del modello ponderate\n",
        "for num in predictions[-1].astype(int):\n",
        "    if num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Aggiungi i numeri più frequenti ponderati\n",
        "for num in numeri_ordinati_frequenza[:5]:\n",
        "    if num[0] not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num[0])\n",
        "\n",
        "# Aggiungi i numeri ritardatari ponderati\n",
        "for num in ritardatari[:3]:\n",
        "    if num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Se non raggiungi 6 numeri, prendi numeri casuali dai ritardatari\n",
        "while len(previsione_combinata_ottimizzata) < 6:\n",
        "    random_number = np.random.choice(ritardatari)  # Aggiungi un numero ritardatario casuale\n",
        "    if random_number not in previsione_combinata_ottimizzata:\n",
        "        previsione_combinata_ottimizzata.append(random_number)\n",
        "\n",
        "# Stampa la previsione finale ottimizzata\n",
        "print(f\"\\nPrevisione finale ottimizzata: {previsione_combinata_ottimizzata}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU0m89s0hjKG",
        "outputId": "03d593c4-151d-4b2e-e659-21803362f92e"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migliori pesi trovati: modello=0.0, statistica=0.0\n",
            "Precisione media ottenuta: 0.57\n",
            "\n",
            "Previsione finale ottimizzata: [10, 18, 15, 31, 72.0, 40.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsione finale ottimizzata: senza duplicati e con numeri interi\n",
        "previsione_combinata_ottimizzata = []\n",
        "\n",
        "# Aggiungi la percentuale di ottimizzazione\n",
        "percentuale_model = peso_model_ottimizzato * 100  # Pesi ottimizzati per il modello, espressi come percentuali\n",
        "percentuale_stat = peso_stat_ottimizzato * 100  # Pesi ottimizzati per la statistica, espressi come percentuali\n",
        "\n",
        "# Prendi l'ultima estrazione\n",
        "ultima_estrazione = df_cleaned.tail(1).values.flatten()  # Consideriamo l'ultima estrazione, se necessario puoi regolare questo\n",
        "\n",
        "# Aggiungi le previsioni ponderate (senza duplicati)\n",
        "previsione_combinata_ottimizzata.extend([int(num) for num in predictions[-1].astype(int)[:int(6 * peso_model_ottimizzato)]])\n",
        "\n",
        "# Aggiungi i numeri frequenti ponderati (senza duplicati)\n",
        "previsione_combinata_ottimizzata.extend([num for num, _ in numeri_ordinati_frequenza[:int(6 * peso_stat_ottimizzato)]])\n",
        "\n",
        "# Aggiungi numeri ritardatari se necessario (senza duplicati)\n",
        "for num in ritardatari[:3]:\n",
        "    # Check if num is not NaN before appending\n",
        "    if not pd.isnull(num) and num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Elimina duplicati dalla previsione finale\n",
        "previsione_combinata_ottimizzata = list(set(previsione_combinata_ottimizzata))\n",
        "\n",
        "# Rimuovi i numeri che sono già usciti nell'ultima estrazione\n",
        "previsione_combinata_ottimizzata = [num for num in previsione_combinata_ottimizzata if num not in ultima_estrazione]\n",
        "\n",
        "# Se ci sono meno di 6 numeri, aggiungi numeri mancanti dalla lista dei numeri ritardatari\n",
        "while len(previsione_combinata_ottimizzata) < 6:\n",
        "    for rit in ritardatari:\n",
        "        # Check if rit is not NaN before appending\n",
        "        if not pd.isnull(rit) and rit not in previsione_combinata_ottimizzata:\n",
        "            previsione_combinata_ottimizzata.append(rit)\n",
        "        if len(previsione_combinata_ottimizzata) == 6:\n",
        "            break\n",
        "\n",
        "# Convertili tutti in interi\n",
        "previsione_combinata_ottimizzata = [int(num) for num in previsione_combinata_ottimizzata]\n",
        "\n",
        "# Stampa la previsione finale con la percentuale di ottimizzazione\n",
        "print(f\"\\nPrevisione finale ottimizzata:\")\n",
        "print(f\"Numeri previsti: {previsione_combinata_ottimizzata}\")\n",
        "print(f\"Percentuale ottimizzata per il modello: {percentuale_model:.2f}%\")\n",
        "print(f\"Percentuale ottimizzata per la statistica: {percentuale_stat:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWVIgjN3iIoJ",
        "outputId": "122fc18c-d9d3-49fc-8ef5-1a6dcce5185d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previsione finale ottimizzata:\n",
            "Numeri previsti: [72, 40, 10, 41, 18, 2]\n",
            "Percentuale ottimizzata per il modello: 50.00%\n",
            "Percentuale ottimizzata per la statistica: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previsione e salvataggio in CSV"
      ],
      "metadata": {
        "id": "vN5JOXpoQ9EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "ultima_sequenza = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
        "predizione = modello.predict(ultima_sequenza)\n",
        "\n",
        "# Denormalizza la predizione per riportare i valori tra 1 e 90\n",
        "predizione_denorm = scaler.inverse_transform(predizione)\n",
        "\n",
        "# Arrotonda e limita i valori tra 1 e 90\n",
        "def trasforma_predizione(predizione_denorm):\n",
        "    predizione_arrotondata = np.round(predizione_denorm).astype(int)  # Arrotonda e converte in int\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Assicura i numeri validi\n",
        "    return predizione_arrotondata\n",
        "\n",
        "# Applica la trasformazione\n",
        "predizione_interi = trasforma_predizione(predizione_denorm)\n",
        "\n",
        "# Controllo prima di salvare\n",
        "print(f\"Predizione della prossima estrazione: {predizione_interi.flatten()}\")\n",
        "\n",
        "# Creazione del DataFrame con il formato corretto\n",
        "df_predizione = pd.DataFrame(predizione_interi, columns=[\"Num1\", \"Num2\", \"Num3\", \"Num4\", \"Num5\"])\n",
        "\n",
        "# Salvataggio corretto in CSV\n",
        "csv_path = \"/content/prossima_estrazione.csv\"\n",
        "df_predizione.to_csv(csv_path, index=False, header=True)\n",
        "\n",
        "print(f\"File CSV salvato correttamente in {csv_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUs7OtVPQ_ks",
        "outputId": "fb5595d1-c08b-44c8-f8af-ad662dbe34f7"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "Predizione della prossima estrazione: [1 1 1 1 1]\n",
            "File CSV salvato correttamente in /content/prossima_estrazione.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-0635bc2e6773>:13: RuntimeWarning: invalid value encountered in cast\n",
            "  predizione_arrotondata = np.round(predizione_denorm).astype(int)  # Arrotonda e converte in int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import zipfile\n",
        "\n",
        "file_path = '/content/it-superenalotto-past-draws-archive.zip'\n",
        "\n",
        "def carica_database(file_path):\n",
        "    # Estrai il file .xls dal file .zip\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        xls_file = zip_ref.namelist()[0]  # Ottieni il nome del file .xls all'interno dello zip\n",
        "        with zip_ref.open(xls_file) as file:\n",
        "            # Leggi il file Excel usando il file estratto\n",
        "            df = pd.read_excel(file, engine='xlrd', skiprows=1)\n",
        "    # Prende solo numeri e rimuove colonne vuote\n",
        "    numeri_estratti = df.select_dtypes(include='number').dropna(axis=1, how='all')\n",
        "\n",
        "    # Usa solo le ultime 50 estrazioni 🔥\n",
        "    numeri_estratti = numeri_estratti.tail(50)\n",
        "    return numeri_estratti\n",
        "\n",
        "def calcola_frequenze(df):\n",
        "    frequenze = df.stack().value_counts()\n",
        "    return frequenze.head(5).index.tolist()\n",
        "\n",
        "def calcola_ritardatari(df):\n",
        "    numeri_totali = set(range(1, 91))\n",
        "    ultime_uscite = {}\n",
        "\n",
        "    for numero in numeri_totali:\n",
        "        try:\n",
        "            ultima_pos = df.apply(lambda colonna: numero in colonna.values).iloc[::-1].idxmax()\n",
        "            ultime_uscite[numero] = ultima_pos\n",
        "        except:\n",
        "            ultime_uscite[numero] = -1\n",
        "\n",
        "    ritardatari = sorted(ultime_uscite, key=ultime_uscite.get, reverse=True)[:5]\n",
        "    return ritardatari\n",
        "\n",
        "def somma_90(previsione):\n",
        "    somma = (previsione[0] + previsione[1]) % 90\n",
        "    if somma == 0:\n",
        "        somma = 90\n",
        "    return somma\n",
        "\n",
        "# Esegui tutto\n",
        "df = carica_database(file_path)\n",
        "numeri_frequenti = calcola_frequenze(df)\n",
        "numeri_ritardatari = calcola_ritardatari(df)\n",
        "previsione = numeri_frequenti + numeri_ritardatari\n",
        "somma = somma_90(previsione)\n",
        "\n",
        "print(f\"Data aggiornamento: {datetime.date.today()}\")\n",
        "print(\"Numeri più frequenti:\", numeri_frequenti)\n",
        "print(\"Numeri ritardatari:\", numeri_ritardatari)\n",
        "print(\"Previsione Finale:\", previsione)\n",
        "print(\"🔥 Somma 90:\", somma)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOqNKLh13XVe",
        "outputId": "e7619a0f-12bb-4829-d8c9-62109e8ee3e8"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
            "Data aggiornamento: 2025-03-10\n",
            "Numeri più frequenti: [72.0, 77.0, 40.0, 41.0, 85.0]\n",
            "Numeri ritardatari: [1, 6, 8, 9, 13]\n",
            "Previsione Finale: [72.0, 77.0, 40.0, 41.0, 85.0, 1, 6, 8, 9, 13]\n",
            "🔥 Somma 90: 59.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1KGV-7aJYOu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previsione Finale\n"
      ],
      "metadata": {
        "id": "ke-VWxBXV-Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Caricamento delle ultime 10 estrazioni\n",
        "file_path = '/content/it-superenalotto-past-draws-archive.zip'\n",
        "df = carica_database(file_path)  # Funzione che abbiamo già definito\n",
        "ultime_estrazioni = df.tail(200).values  # Prendiamo solo i valori numerici\n",
        "\n",
        "# Previsioni ottenute\n",
        "previsione_ml = [26, 36, 57, 70, 90]  # Sostituisci con la tua previsione ML\n",
        "top_numeri_stat = [72, 41, 40, 77, 83, 1, 6, 8, 9, 13]  # Previsione statistica\n",
        "\n",
        "# Funzione per contare i match tra previsione e ultime estrazioni\n",
        "def conta_match(previsione, estrazioni):\n",
        "    match_per_estrazione = [len(set(previsione) & set(estr)) for estr in estrazioni]\n",
        "    totale_match = sum(match_per_estrazione)\n",
        "    return totale_match, match_per_estrazione\n",
        "\n",
        "# Confronto tra previsioni e ultime estrazioni\n",
        "match_ml, dettagli_ml = conta_match(previsione_ml, ultime_estrazioni)\n",
        "match_stat, dettagli_stat = conta_match(top_numeri_stat, ultime_estrazioni)\n",
        "\n",
        "# Analisi frequenze\n",
        "frequenze = df.stack().value_counts().head(15)  # Prendi i 15 numeri più frequenti\n",
        "\n",
        "# Output risultati\n",
        "print(f\"🎯 Confronto con le ultime 10 estrazioni:\")\n",
        "print(f\"✔️ Match con ML: {match_ml} numeri trovati\")\n",
        "print(f\"✔️ Match con Statistica: {match_stat} numeri trovati\")\n",
        "print(\"\\n🔍 Dettaglio delle corrispondenze per ogni estrazione:\")\n",
        "print(f\"ML: {dettagli_ml}\")\n",
        "print(f\"Statistica: {dettagli_stat}\")\n",
        "print(\"\\n🔥 Numeri più frequenti nelle ultime estrazioni:\")\n",
        "print(frequenze)\n",
        "\n",
        "# Suggerimento per la prossima previsione\n",
        "suggeriti = set(frequenze.index[:5]) | set(top_numeri_stat[:5])  # Unione dei top numeri\n",
        "print(\"\\n📌 Numeri suggeriti per la prossima estrazione:\")\n",
        "print(suggeriti)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAB4A51zV_7O",
        "outputId": "d82b9102-74f5-4d00-edb4-c10ee0c081a1"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
            "🎯 Confronto con le ultime 10 estrazioni:\n",
            "✔️ Match con ML: 7 numeri trovati\n",
            "✔️ Match con Statistica: 35 numeri trovati\n",
            "\n",
            "🔍 Dettaglio delle corrispondenze per ogni estrazione:\n",
            "ML: [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Statistica: [0, 0, 1, 0, 0, 0, 1, 3, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 3, 3, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
            "\n",
            "🔥 Numeri più frequenti nelle ultime estrazioni:\n",
            "72.0    9\n",
            "77.0    6\n",
            "40.0    6\n",
            "41.0    6\n",
            "85.0    5\n",
            "63.0    5\n",
            "83.0    5\n",
            "30.0    5\n",
            "29.0    5\n",
            "59.0    4\n",
            "87.0    4\n",
            "25.0    4\n",
            "49.0    4\n",
            "74.0    4\n",
            "86.0    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "📌 Numeri suggeriti per la prossima estrazione:\n",
            "{72.0, 41.0, 40.0, 77.0, 83, 85.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PTKiL26PWlVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Funzione migliorata per preparare i dati (controllo dei NaN)\n",
        "def prepara_dati(df_cleaned, sequenza_lenght=5):\n",
        "    sequenze = []\n",
        "    target = []\n",
        "\n",
        "    for i in range(len(df_cleaned) - sequenza_lenght):\n",
        "        # Estrazione dei numeri per la sequenza\n",
        "        sequenza = df_cleaned.iloc[i:i + sequenza_lenght].values.flatten()\n",
        "\n",
        "        # Se la sequenza contiene NaN, la scartiamo\n",
        "        if np.any(np.isnan(sequenza)):\n",
        "            continue\n",
        "\n",
        "        sequenze.append(sequenza)\n",
        "        target.append(df_cleaned.iloc[i + sequenza_lenght].values.flatten())\n",
        "\n",
        "    X = np.array(sequenze)\n",
        "    y = np.array(target)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Prepara i dati\n",
        "X, y = prepara_dati(df_cleaned)\n",
        "\n",
        "# Verifica la forma dei dati\n",
        "print(f\"Forma di X: {X.shape}\")\n",
        "print(f\"Forma di y: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkS8_GdaNEes",
        "outputId": "b7a38857-a486-4718-c238-e05bb0a71720"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma di X: (33, 25)\n",
            "Forma di y: (33, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVpbyqlfMO5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terza Cella: Prepara i dati per l'allenamento"
      ],
      "metadata": {
        "id": "b9lin5HxYQ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Funzione per preparare i dati: crea sequenze temporali\n",
        "def prepara_dati(df_cleaned, sequenza_lenght=5):\n",
        "    sequenze = []\n",
        "    target = []\n",
        "\n",
        "    # Cicliamo per creare le sequenze\n",
        "    for i in range(len(df_cleaned) - sequenza_lenght):\n",
        "        sequenza = df_cleaned.iloc[i:i + sequenza_lenght].values.flatten()\n",
        "        sequenze.append(sequenza)\n",
        "        target.append(df_cleaned.iloc[i + sequenza_lenght].values.flatten())\n",
        "\n",
        "    # Convertiamo in array numpy\n",
        "    X = np.array(sequenze)\n",
        "    y = np.array(target)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Prepara i dati per l'allenamento\n",
        "X, y = prepara_dati(df_cleaned)\n",
        "\n",
        "# Mostra la forma di X e y per verificarne la corretta preparazione\n",
        "print(f\"Forma di X: {X.shape}\")\n",
        "print(f\"Forma di y: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_JjqVnmMXXC",
        "outputId": "81a58cff-ad0b-461a-985e-2a8e4cb7ed8d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma di X: (35, 25)\n",
            "Forma di y: (35, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quarta Cella: Creazione e allenamento del modello"
      ],
      "metadata": {
        "id": "RkX18yi1XBhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Creazione del modello di rete neurale\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))  # Primo strato\n",
        "model.add(Dense(64, activation='relu'))  # Secondo strato\n",
        "model.add(Dense(y.shape[1], activation='linear'))  # Strato di uscita per predizioni numeriche\n",
        "\n",
        "# Compilazione del modello con una funzione di perdita appropriata per la regressione\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Allenamento del modello\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Salviamo il modello allenato per usi futuri\n",
        "model.save(\"/content/lotto_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6stSJ2MizJ",
        "outputId": "10a16a2b-9fe5-4ac2-91cd-1a89d875d01d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se X è 2D, aggiungiamo una dimensione per le caratteristiche\n",
        "if len(X.shape) == 2:\n",
        "    X = np.expand_dims(X, axis=-1)  # Aggiungiamo una dimensione per le features\n",
        "\n",
        "print(X.shape)  # Ora X dovrebbe essere (n_samples, sequence_length, 1)\n",
        "\n",
        "# Creazione del modello LSTM\n",
        "modello = Sequential()\n",
        "modello.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "modello.add(LSTM(units=50))\n",
        "modello.add(Dense(units=5))  # Predizione di 5 numeri per ogni sequenza\n",
        "\n",
        "# Compilazione del modello\n",
        "modello.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Addestramento del modello\n",
        "modello.fit(X, y, epochs=10, batch_size=32)\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "predizione = modello.predict(X[-1].reshape(1, X.shape[1], X.shape[2]))  # Utilizza l'ultima sequenza per la previsione\n",
        "\n",
        "# Funzione per trasformare la previsione in numeri interi tra 1 e 90\n",
        "def trasforma_predizione(predizione):\n",
        "    predizione_arrotondata = np.round(predizione)  # Arrotonda i valori continui\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Limita i valori tra 1 e 90\n",
        "    return predizione_arrotondata.astype(int)  # Converte in interi\n",
        "\n",
        "# Trasforma la predizione in numeri interi da 1 a 90\n",
        "predizione_interi = trasforma_predizione(predizione)\n",
        "# Se X è 2D, aggiungiamo una dimensione per le caratteristiche\n",
        "if len(X.shape) == 2:\n",
        "    X = np.expand_dims(X, axis=-1)  # Aggiungiamo una dimensione per le features\n",
        "\n",
        "print(X.shape)  # Ora X dovrebbe essere (n_samples, sequence_length, 1)\n",
        "\n",
        "# Creazione del modello LSTM\n",
        "modello = Sequential()\n",
        "modello.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "modello.add(LSTM(units=50))\n",
        "modello.add(Dense(units=5))  # Predizione di 5 numeri per ogni sequenza\n",
        "\n",
        "# Compilazione del modello\n",
        "modello.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Addestramento del modello\n",
        "modello.fit(X, y, epochs=10, batch_size=32)\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "predizione = modello.predict(X[-1].reshape(1, X.shape[1], X.shape[2]))  # Utilizza l'ultima sequenza per la previsione\n",
        "\n",
        "# Funzione per trasformare la previsione in numeri interi tra 1 e 90\n",
        "def trasforma_predizione(predizione):\n",
        "    predizione_arrotondata = np.round(predizione)  # Arrotonda i valori continui\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Limita i valori tra 1 e 90\n",
        "    return predizione_arrotondata.astype(int)  # Converte in interi\n",
        "\n",
        "# Trasforma la predizione in numeri interi da 1 a 90\n",
        "predizione_interi = trasforma_predizione(predizione)\n",
        "\n",
        "print(f\"Predizione della prossima estrazione: {predizione_interi}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHtK4zKQN0Ni",
        "outputId": "788397ca-0b8e-42e0-85eb-de1fab93f226"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35, 25, 1)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: nan \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79a9e5ae6fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "(35, 25, 1)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-eb2057967d88>:26: RuntimeWarning: invalid value encountered in cast\n",
            "  return predizione_arrotondata.astype(int)  # Converte in interi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan \n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79a9edacab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "Predizione della prossima estrazione: [[-9223372036854775808 -9223372036854775808 -9223372036854775808\n",
            "  -9223372036854775808 -9223372036854775808]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-eb2057967d88>:55: RuntimeWarning: invalid value encountered in cast\n",
            "  return predizione_arrotondata.astype(int)  # Converte in interi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quinta Cella: Fare previsioni"
      ],
      "metadata": {
        "id": "29NF5kYVXNf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "noooo"
      ],
      "metadata": {
        "id": "B2aWE5ZSXW28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "next step"
      ],
      "metadata": {
        "id": "ti2A1-cGXij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Genera una previsione (esempio semplificato)\n",
        "# La previsione si basa sui numeri più frequenti\n",
        "previsione = numeri_frequenti"
      ],
      "metadata": {
        "id": "R8LasAQU3aS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "a4959add-5777-4ba4-d9eb-f45cdf30d947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'numeri_frequenti' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-318e02fd9b0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Genera una previsione (esempio semplificato)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# La previsione si basa sui numeri più frequenti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprevisione\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeri_frequenti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'numeri_frequenti' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un DataFrame per la previsione\n",
        "previsione_df = pd.DataFrame({'Numero': previsione})\n"
      ],
      "metadata": {
        "id": "_hMO6Nnx3dKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva la previsione in un file CSV\n",
        "previsione_df.to_csv('/content/previsione_lotto.csv', index=False)\n",
        "\n",
        "print(\"Previsione salvata in /content/previsione_lotto.csv\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/previsione_lotto.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gimKnDF-3gD1",
        "outputId": "e859db19-4ec3-446e-9f34-876731daf8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsione salvata in /content/previsione_lotto.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db4c86d1-f896-4b35-b8f0-c4c98b3cb7f7\", \"previsione_lotto.csv\", 30)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Un benvenuto a Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}