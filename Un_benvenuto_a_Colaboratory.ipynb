{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcasaldi/CS50/blob/main/Un_benvenuto_a_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxjvmwmCz0_A",
        "outputId": "a613999e-6132-443e-beba-f2eb83886af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caricare file .txt e visualizzare il file"
      ],
      "metadata": {
        "id": "fCN31-0ddtsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creare il DataFrame con i numeri estratti\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rfDft9uye0dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "xojliKgxjso5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Carica il file .zip\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Estrazione del contenuto del file .zip\n",
        "for fn in uploaded.keys():\n",
        "    if fn.endswith(\".zip\"):\n",
        "        # Creiamo una cartella per estrarre i file\n",
        "        extract_folder = '/content/extracted_files'\n",
        "        os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "        # Estraiamo i contenuti del .zip\n",
        "        with zipfile.ZipFile(fn, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_folder)\n",
        "            print(f\"File estratti in: {extract_folder}\")\n",
        "\n",
        "# Lista i file estratti per assicurarti che ci sia un .txt\n",
        "extracted_files = os.listdir(extract_folder)\n",
        "print(\"File estratti:\", extracted_files)\n",
        "\n",
        "# Se c'Ã¨ un file .txt, lo leggiamo\n",
        "for file in extracted_files:\n",
        "    if file.endswith(\".txt\"):\n",
        "        txt_file_path = os.path.join(extract_folder, file)\n",
        "        with open(txt_file_path, 'r') as f:\n",
        "            data = f.readlines()\n",
        "\n",
        "        print(f\"Contenuto del file {file}:\\n\")\n",
        "        print(data[:10])  # Visualizza le prime 5 righe per verificarne il contenuto\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "iAVMUEa3julY",
        "outputId": "e274705e-6469-4955-dd90-30682d249671"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8d49f7a-8d69-4293-b978-6d3bd69ecafa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d8d49f7a-8d69-4293-b978-6d3bd69ecafa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SuperEnalotto-archivio-estrazioni-2025.zip to SuperEnalotto-archivio-estrazioni-2025.zip\n",
            "File estratti in: /content/extracted_files\n",
            "File estratti: ['SuperEnalotto-archivio-estrazioni-2025.txt']\n",
            "Contenuto del file SuperEnalotto-archivio-estrazioni-2025.txt:\n",
            "\n",
            "['SuperEnalotto\\n', 'Archivio estrazioni SuperEnalotto anno 2025 aggiornato al 11/03/2025\\n', 'Concorso\\tData\\tN.1\\tN.2\\tN.3\\tN.4\\tN.5\\tN.6\\tJolly\\tSuperStar\\t\\n', '40\\t11/03/2025\\t22\\t27\\t48\\t55\\t58\\t90\\t63\\t11\\t\\n', '39\\t08/03/2025\\t11\\t16\\t35\\t59\\t65\\t87\\t9\\t52\\t\\n', '38\\t07/03/2025\\t11\\t24\\t25\\t30\\t43\\t47\\t28\\t5\\t\\n', '37\\t06/03/2025\\t1\\t10\\t18\\t19\\t32\\t36\\t20\\t53\\t\\n', '36\\t04/03/2025\\t9\\t28\\t52\\t63\\t77\\t79\\t11\\t39\\t\\n', '35\\t01/03/2025\\t1\\t12\\t33\\t40\\t41\\t83\\t6\\t67\\t\\n', '34\\t28/02/2025\\t4\\t12\\t37\\t59\\t63\\t90\\t70\\t15\\t\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ripulire\n"
      ],
      "metadata": {
        "id": "WZlX4Sbigqs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Percorso del file .txt estratto\n",
        "txt_file_path = '/content/extracted_files/SuperEnalotto-archivio-estrazioni-2025.txt'\n",
        "\n",
        "# Leggi il file\n",
        "with open(txt_file_path, 'r') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# Pulizia e parsing dei dati\n",
        "data_cleaned = [line.strip().split('\\t') for line in data]\n",
        "\n",
        "# Trova l'indice della riga di intestazione (dovrebbe essere la terza riga)\n",
        "header_index = next(i for i, row in enumerate(data_cleaned) if \"Concorso\" in row)\n",
        "\n",
        "# Estrai i dati a partire dall'intestazione\n",
        "columns = data_cleaned[header_index]\n",
        "rows = data_cleaned[header_index + 1:]\n",
        "\n",
        "# Creazione del DataFrame\n",
        "df = pd.DataFrame(rows, columns=columns)\n",
        "\n",
        "# Converte i numeri da stringhe a interi\n",
        "df.iloc[:, 2:] = df.iloc[:, 2:].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Visualizza le prime estrazioni per controllo\n",
        "print(\"Prime 10 estrazioni del SuperEnalotto:\")\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "850nhWHegs8G",
        "outputId": "42b8dfc5-5f13-4d00-c98b-cc25719e5ed2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prime 10 estrazioni del SuperEnalotto:\n",
            "  Concorso        Data N.1 N.2 N.3 N.4 N.5 N.6 Jolly SuperStar\n",
            "0       40  11/03/2025  22  27  48  55  58  90    63        11\n",
            "1       39  08/03/2025  11  16  35  59  65  87     9        52\n",
            "2       38  07/03/2025  11  24  25  30  43  47    28         5\n",
            "3       37  06/03/2025   1  10  18  19  32  36    20        53\n",
            "4       36  04/03/2025   9  28  52  63  77  79    11        39\n",
            "5       35  01/03/2025   1  12  33  40  41  83     6        67\n",
            "6       34  28/02/2025   4  12  37  59  63  90    70        15\n",
            "7       33  27/02/2025  29  31  33  42  51  72    34        62\n",
            "8       32  25/02/2025   6  58  68  83  89  90    73        50\n",
            "9       31  22/02/2025  35  40  48  49  52  89    24        32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creazione del Dataset"
      ],
      "metadata": {
        "id": "uN4AUcap2CsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PDNh8x5Z2T2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supponiamo che 'df' sia il DataFrame giÃ  creato\n",
        "# Creazione del Dataset\n",
        "data = []\n",
        "for i in range(len(df) - 1):\n",
        "    current_row = df.iloc[i]\n",
        "    next_row = df.iloc[i + 1]\n",
        "\n",
        "    # Correggi la selezione delle colonne:\n",
        "    # Seleziona tutte le colonne numeriche (N1, N2, ..., Jolly, SuperStar)\n",
        "    data.append(current_row[['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']].tolist() +\n",
        "                next_row[['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']].tolist())\n",
        "\n",
        "# Creiamo un nuovo DataFrame\n",
        "columns = ['N.1', 'N.2', 'N.3', 'N.4', 'N.5', 'N.6', 'Jolly', 'SuperStar'] + ['Next_N.1', 'Next_N.2', 'Next_N.3', 'Next_N.4', 'Next_N.5', 'Next_N.6', 'Next_Jolly', 'Next_SuperStar']\n",
        "training_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Visualizziamo il DataFrame di training\n",
        "print(training_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzK1iJ0E2Dd3",
        "outputId": "379460ce-ced1-4517-cf20-09406909728b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   N.1  N.2  N.3  N.4  N.5  N.6  Jolly  SuperStar  Next_N.1  Next_N.2  \\\n",
            "0   22   27   48   55   58   90     63         11        11        16   \n",
            "1   11   16   35   59   65   87      9         52        11        24   \n",
            "2   11   24   25   30   43   47     28          5         1        10   \n",
            "3    1   10   18   19   32   36     20         53         9        28   \n",
            "4    9   28   52   63   77   79     11         39         1        12   \n",
            "\n",
            "   Next_N.3  Next_N.4  Next_N.5  Next_N.6  Next_Jolly  Next_SuperStar  \n",
            "0        35        59        65        87           9              52  \n",
            "1        25        30        43        47          28               5  \n",
            "2        18        19        32        36          20              53  \n",
            "3        52        63        77        79          11              39  \n",
            "4        33        40        41        83           6              67  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addestramento del Modello"
      ],
      "metadata": {
        "id": "WTPnGu4y2b2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supponiamo che 'df' sia il DataFrame giÃ  creato\n",
        "# Creazione del Dataset\n",
        "data = []\n",
        "for i in range(len(df) - 1):\n",
        "    current_row = df.iloc[i]\n",
        "    next_row = df.iloc[i + 1]\n",
        "\n",
        "    # Correggi la selezione delle colonne:\n",
        "    # Seleziona tutte le colonne numeriche (N1, N2, ..., Jolly, SuperStar)\n",
        "    data.append(current_row[['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']].tolist() +\n",
        "                next_row[['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']].tolist())\n",
        "\n",
        "# Creiamo un nuovo DataFrame\n",
        "columns = ['N.1', 'N.2', 'N.3', 'N.4', 'N.5', 'N.6', 'Jolly', 'SuperStar'] + ['Next_N.1', 'Next_N.2', 'Next_N.3', 'Next_N.4', 'Next_N.5', 'Next_N.6', 'Next_Jolly', 'Next_SuperStar']\n",
        "training_df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Visualizziamo il DataFrame di training\n",
        "print(training_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tc0p3SC2emQ",
        "outputId": "b28a12c8-b792-4e9e-c49e-74bbed85deec"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   N.1  N.2  N.3  N.4  N.5  N.6  Jolly  SuperStar  Next_N.1  Next_N.2  \\\n",
            "0   22   27   48   55   58   90     63         11        11        16   \n",
            "1   11   16   35   59   65   87      9         52        11        24   \n",
            "2   11   24   25   30   43   47     28          5         1        10   \n",
            "3    1   10   18   19   32   36     20         53         9        28   \n",
            "4    9   28   52   63   77   79     11         39         1        12   \n",
            "\n",
            "   Next_N.3  Next_N.4  Next_N.5  Next_N.6  Next_Jolly  Next_SuperStar  \n",
            "0        35        59        65        87           9              52  \n",
            "1        25        30        43        47          28               5  \n",
            "2        18        19        32        36          20              53  \n",
            "3        52        63        77        79          11              39  \n",
            "4        33        40        41        83           6              67  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previsione della Prossima Estrazione"
      ],
      "metadata": {
        "id": "zZ9TLIzg2jDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: allena il modello e fai la previsione\n",
        "\n",
        "# Preparazione dei dati per il modello\n",
        "X = training_df.drop(columns=['Next_N.1', 'Next_N.2', 'Next_N.3', 'Next_N.4', 'Next_N.5', 'Next_N.6', 'Next_Jolly', 'Next_SuperStar'])\n",
        "y = training_df[['Next_N.1', 'Next_N.2', 'Next_N.3', 'Next_N.4', 'Next_N.5', 'Next_N.6', 'Next_Jolly', 'Next_SuperStar']]\n",
        "\n",
        "# Dividi i dati in set di training e testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardizzazione dei dati\n",
        "scaler_x = StandardScaler()\n",
        "X_train = scaler_x.fit_transform(X_train)\n",
        "X_test = scaler_x.transform(X_test)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_train = scaler_y.fit_transform(y_train)\n",
        "y_test = scaler_y.transform(y_test)\n",
        "\n",
        "# Crea e addestra il modello (esempio con una rete neurale)\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1]))  # Output layer con 8 neuroni\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1) # Riduce le epoche per test rapidi\n",
        "\n",
        "# Previsione sulla base dell'ultima riga del DataFrame originale\n",
        "last_row = df.iloc[-1][['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']].values.reshape(1,-1)\n",
        "last_row_scaled = scaler_x.transform(last_row)\n",
        "prediction_scaled = model.predict(last_row_scaled)\n",
        "\n",
        "# Inverto la standardizzazione per ottenere i numeri originali\n",
        "prediction = scaler_y.inverse_transform(prediction_scaled)\n",
        "\n",
        "# Arrotonda i valori previsti (i numeri del lotto sono interi)\n",
        "prediction_rounded = np.round(prediction).astype(int)\n",
        "\n",
        "\n",
        "print(\"Prossima estrazione prevista:\")\n",
        "prediction_rounded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etyor-oABZWW",
        "outputId": "b58c3148-9f72-458f-9ccc-e65195e5a004"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.1284\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 1.0905\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.0577\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.0292\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.0047\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.9836\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.9651\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.9486\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.9335\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.9197\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9067\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.8945\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8829\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.8716\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.8606\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.8499\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.8397\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.8296\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.8198\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.8100\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.8002\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.7904\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7806\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7709\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.7613\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7517\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7419\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7319\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.7218\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7119\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7020\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6919\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.6818\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6716\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.6613\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6508\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.6402\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.6294\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.6187\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6081\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.5977\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.5873\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5768\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.5664\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.5560\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5457\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.5356\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5255\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.5155\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5055\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4957\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4860\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4763\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.4664\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.4568\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4475\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4383\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.4292\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4202\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.4113\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.4025\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3939\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3854\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.3770\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3688\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3606\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3527\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.3448\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3370\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3294\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3219\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3146\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.3073\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.3001\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.2931\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2861\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2793\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2726\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2661\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.2597\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2534\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2472\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.2411\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2351\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2293\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2235\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2179\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2124\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.2070\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.2017\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.1963\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1911\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1861\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1811\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1761\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1713\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1666\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1620\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1576\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1531\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Prossima estrazione prevista:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8, 21, 16, 51, 59, 65, 65, 33]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: allena di nuovo il modello con piÃ¹ sicurezza sulla base statistica dei numeri usciti. tieni da conto quelli che escono di piÃ¹ e quelli che sono in ritardo. tieni da conto le estrazioni storiche giÃ  uscite e fai un training sofisticato che sia preciso sulla prossima estrazione\n",
        "\n",
        "# ... (Your existing code)\n",
        "\n",
        "# Feature Engineering: Include historical frequency and recency of numbers\n",
        "from collections import Counter # Import Counter from collections module\n",
        "\n",
        "def calculate_frequencies(df, column_name, window_size=50): # Add window size parameter\n",
        "    frequencies = []\n",
        "    for i in range(len(df)):\n",
        "        # Calculate frequencies within the sliding window\n",
        "        window = df[column_name][max(0, i - window_size + 1):i + 1]\n",
        "        counts = Counter(window)\n",
        "        frequencies.append({num: count for num, count in counts.items()})\n",
        "    return frequencies\n",
        "\n",
        "\n",
        "# Apply to all relevant columns (N1-N6, Jolly, SuperStar)\n",
        "for col in ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'Jolly', 'SuperStar']:\n",
        "    df[f'{col}_freq'] = calculate_frequencies(df, col)\n",
        "\n",
        "\n",
        "# ... (rest of your data preprocessing code)\n",
        "\n",
        "# Model Training (using a more complex model and more data)\n",
        "\n",
        "# ... (your existing model code)\n",
        "\n",
        "# Consider a deeper neural network or other suitable models like LSTM or Random Forest\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))  # Increased neurons\n",
        "model.add(Dropout(0.2))  # Add dropout for regularization\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(y_train.shape[1]))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Increase the number of epochs and adjust the batch size as needed\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=1) # Increased Epochs and batch size\n",
        "\n",
        "# ... (rest of your prediction code)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "\n",
        "print(\"Prossima estrazione prevista:\")\n",
        "prediction_rounded\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVLnrldwBj0_",
        "outputId": "b67b1fcd-b718-4f2b-b2c2-84c1d12f25a3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 1.0156\n",
            "Epoch 2/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.0208\n",
            "Epoch 3/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.9706\n",
            "Epoch 4/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.9832\n",
            "Epoch 5/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.9680\n",
            "Epoch 6/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.9448\n",
            "Epoch 7/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.9341\n",
            "Epoch 8/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.9280\n",
            "Epoch 9/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.9280\n",
            "Epoch 10/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.9082\n",
            "Epoch 11/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.8983\n",
            "Epoch 12/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.8718\n",
            "Epoch 13/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8569\n",
            "Epoch 14/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.8467\n",
            "Epoch 15/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.8583\n",
            "Epoch 16/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.7976\n",
            "Epoch 17/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.8045\n",
            "Epoch 18/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7834\n",
            "Epoch 19/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7905\n",
            "Epoch 20/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.7809\n",
            "Epoch 21/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.7419\n",
            "Epoch 22/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.7560\n",
            "Epoch 23/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7579\n",
            "Epoch 24/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.7235\n",
            "Epoch 25/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.7217\n",
            "Epoch 26/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7130\n",
            "Epoch 27/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.7097\n",
            "Epoch 28/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.6882\n",
            "Epoch 29/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7171\n",
            "Epoch 30/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.6706\n",
            "Epoch 31/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.6125\n",
            "Epoch 32/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.6603\n",
            "Epoch 33/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6290\n",
            "Epoch 34/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6292\n",
            "Epoch 35/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.6135\n",
            "Epoch 36/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5732\n",
            "Epoch 37/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.5773\n",
            "Epoch 38/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5790\n",
            "Epoch 39/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.5286\n",
            "Epoch 40/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.5755\n",
            "Epoch 41/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.5466\n",
            "Epoch 42/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.5727\n",
            "Epoch 43/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.5020\n",
            "Epoch 44/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - loss: 0.5406\n",
            "Epoch 45/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.4871\n",
            "Epoch 46/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.5046\n",
            "Epoch 47/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.5171\n",
            "Epoch 48/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.4532\n",
            "Epoch 49/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - loss: 0.5056\n",
            "Epoch 50/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.4546\n",
            "Epoch 51/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4513\n",
            "Epoch 52/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4291\n",
            "Epoch 53/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.4129\n",
            "Epoch 54/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.4213\n",
            "Epoch 55/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.4111\n",
            "Epoch 56/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.4423\n",
            "Epoch 57/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4139\n",
            "Epoch 58/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.3604\n",
            "Epoch 59/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3694\n",
            "Epoch 60/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3829\n",
            "Epoch 61/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4215\n",
            "Epoch 62/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.3463\n",
            "Epoch 63/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3981\n",
            "Epoch 64/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.3726\n",
            "Epoch 65/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.3742\n",
            "Epoch 66/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.3743\n",
            "Epoch 67/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.3596\n",
            "Epoch 68/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3359\n",
            "Epoch 69/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3420\n",
            "Epoch 70/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3731\n",
            "Epoch 71/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3635\n",
            "Epoch 72/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3109\n",
            "Epoch 73/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.3509\n",
            "Epoch 74/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.3261\n",
            "Epoch 75/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3011\n",
            "Epoch 76/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3084\n",
            "Epoch 77/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2960\n",
            "Epoch 78/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3274\n",
            "Epoch 79/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2719\n",
            "Epoch 80/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.2747\n",
            "Epoch 81/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2559\n",
            "Epoch 82/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.2843\n",
            "Epoch 83/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.3049\n",
            "Epoch 84/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.2780\n",
            "Epoch 85/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2669\n",
            "Epoch 86/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2716\n",
            "Epoch 87/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2404\n",
            "Epoch 88/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2775\n",
            "Epoch 89/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2444\n",
            "Epoch 90/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.2408\n",
            "Epoch 91/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.2662\n",
            "Epoch 92/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2870\n",
            "Epoch 93/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.2354\n",
            "Epoch 94/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2241\n",
            "Epoch 95/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2585\n",
            "Epoch 96/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.2436\n",
            "Epoch 97/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.2102\n",
            "Epoch 98/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.2338\n",
            "Epoch 99/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.2386\n",
            "Epoch 100/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.2169\n",
            "Epoch 101/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2327\n",
            "Epoch 102/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2010\n",
            "Epoch 103/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.2250\n",
            "Epoch 104/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.2088\n",
            "Epoch 105/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.2478\n",
            "Epoch 106/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2166\n",
            "Epoch 107/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.2170\n",
            "Epoch 108/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2509\n",
            "Epoch 109/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.2177\n",
            "Epoch 110/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.1833\n",
            "Epoch 111/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1916\n",
            "Epoch 112/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1943\n",
            "Epoch 113/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1925\n",
            "Epoch 114/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.1965\n",
            "Epoch 115/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.1747\n",
            "Epoch 116/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1904\n",
            "Epoch 117/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1769\n",
            "Epoch 118/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.2183\n",
            "Epoch 119/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1755\n",
            "Epoch 120/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1884\n",
            "Epoch 121/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1791\n",
            "Epoch 122/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1772\n",
            "Epoch 123/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.1961\n",
            "Epoch 124/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1886\n",
            "Epoch 125/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1431\n",
            "Epoch 126/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1710\n",
            "Epoch 127/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1988\n",
            "Epoch 128/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1864\n",
            "Epoch 129/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.2409\n",
            "Epoch 130/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1852\n",
            "Epoch 131/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1767\n",
            "Epoch 132/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1849\n",
            "Epoch 133/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.1874\n",
            "Epoch 134/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1605\n",
            "Epoch 135/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1655\n",
            "Epoch 136/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1608\n",
            "Epoch 137/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.1591\n",
            "Epoch 138/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1818\n",
            "Epoch 139/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1613\n",
            "Epoch 140/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.1651\n",
            "Epoch 141/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1804\n",
            "Epoch 142/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1230\n",
            "Epoch 143/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.2243\n",
            "Epoch 144/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1511\n",
            "Epoch 145/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.1477\n",
            "Epoch 146/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1542\n",
            "Epoch 147/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1633\n",
            "Epoch 148/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.1715\n",
            "Epoch 149/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1497\n",
            "Epoch 150/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1581\n",
            "Epoch 151/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1668\n",
            "Epoch 152/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1488\n",
            "Epoch 153/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1528\n",
            "Epoch 154/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1614\n",
            "Epoch 155/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1197\n",
            "Epoch 156/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.1269\n",
            "Epoch 157/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1347\n",
            "Epoch 158/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1090\n",
            "Epoch 159/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.1341\n",
            "Epoch 160/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1287\n",
            "Epoch 161/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1420\n",
            "Epoch 162/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1392\n",
            "Epoch 163/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1455\n",
            "Epoch 164/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1558\n",
            "Epoch 165/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1202\n",
            "Epoch 166/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1319\n",
            "Epoch 167/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1580\n",
            "Epoch 168/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1321\n",
            "Epoch 169/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1431\n",
            "Epoch 170/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1498\n",
            "Epoch 171/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1390\n",
            "Epoch 172/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1395\n",
            "Epoch 173/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1379\n",
            "Epoch 174/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1301\n",
            "Epoch 175/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1348\n",
            "Epoch 176/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1271\n",
            "Epoch 177/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.1257\n",
            "Epoch 178/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1434\n",
            "Epoch 179/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.1560\n",
            "Epoch 180/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1058\n",
            "Epoch 181/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1243\n",
            "Epoch 182/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.1319\n",
            "Epoch 183/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.1197\n",
            "Epoch 184/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.1380\n",
            "Epoch 185/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1148\n",
            "Epoch 186/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.1033\n",
            "Epoch 187/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1109\n",
            "Epoch 188/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1179\n",
            "Epoch 189/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1128\n",
            "Epoch 190/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1214\n",
            "Epoch 191/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.1108\n",
            "Epoch 192/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.1440\n",
            "Epoch 193/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1068\n",
            "Epoch 194/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1139\n",
            "Epoch 195/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.1255\n",
            "Epoch 196/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.1247\n",
            "Epoch 197/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1284\n",
            "Epoch 198/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0960\n",
            "Epoch 199/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1053\n",
            "Epoch 200/200\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.1153\n",
            "Test Loss: 0.9171026945114136\n",
            "Prossima estrazione prevista:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8, 20, 25, 39, 56, 65, 47, 36]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Carica il file\n",
        "txt_file_path = '/content/extracted_files/SuperEnalotto-archivio-estrazioni-2025.txt'\n",
        "\n",
        "with open(txt_file_path, 'r') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# Step 1: Pulizia dati ed estrazione frequenze e ritardi\n",
        "data_cleaned = data[3:]  # Ignora intestazioni\n",
        "extraction_data = []\n",
        "\n",
        "for line in data_cleaned:\n",
        "    elements = line.strip().split('\\t')\n",
        "    if len(elements) == 10:  # Verifica che ci siano abbastanza colonne\n",
        "        date, num1, num2, num3, num4, num5, num6, jolly, superstar = elements[1:]\n",
        "        extraction_data.append([int(num1), int(num2), int(num3), int(num4), int(num5), int(num6), int(jolly), int(superstar)])\n",
        "\n",
        "df = pd.DataFrame(extraction_data, columns=[\"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"N6\", \"Jolly\", \"SuperStar\"])\n",
        "\n",
        "# Calcolo frequenze di ogni numero\n",
        "all_numbers = df.iloc[:, :6].values.flatten()\n",
        "number_counts = pd.Series(all_numbers).value_counts().sort_index()\n",
        "\n",
        "# Calcolo ritardi (da quante estrazioni manca un numero)\n",
        "latest_occurrence = {}\n",
        "for num in range(1, 91):\n",
        "    occurrences = df[df.iloc[:, :6].eq(num).any(axis=1)].index\n",
        "    latest_occurrence[num] = occurrences[-1] if len(occurrences) > 0 else -1\n",
        "\n",
        "delays = {num: (len(df) - latest_occurrence[num] - 1 if latest_occurrence[num] != -1 else len(df)) for num in range(1, 91)}\n",
        "\n",
        "\n",
        "# Step 2: Predire il range dei numeri piÃ¹ probabili\n",
        "probability_scores = {num: (number_counts.get(num, 0) / len(df) * 100) for num in range(1, 91)}\n",
        "sorted_numbers = sorted(probability_scores.keys(), key=lambda x: (probability_scores[x], -delays[x]), reverse=True)\n",
        "predicted_range = sorted_numbers[:20]  # Prendiamo i 20 numeri piÃ¹ probabili\n",
        "\n",
        "print(f\"ð Numeri piÃ¹ probabili basati su frequenza e ritardo: {predicted_range}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR9bFKUWihde",
        "outputId": "d1bd4db4-f77a-4ea0-dad6-f29b9bbd12ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ð Numeri piÃ¹ probabili basati su frequenza e ritardo: [72, 29, 77, 40, 41, 30, 63, 83, 11, 85, 48, 19, 21, 74, 49, 89, 31, 86, 7, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisi"
      ],
      "metadata": {
        "id": "09j4Mdbolovk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esamina i numeri in predicted_range\n",
        "for num in predicted_range:\n",
        "    freq = number_counts.get(num, 0)  # Frequenza del numero\n",
        "    delay = delays.get(num, 0)  # Ritardo del numero\n",
        "    print(f\"Numero: {num}, Frequenza: {freq}, Ritardo: {delay}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLRupYZalp1M",
        "outputId": "ce80743d-e2fc-40cc-c966-fb2c5806dca9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero: 72, Frequenza: 9, Ritardo: 5\n",
            "Numero: 29, Frequenza: 7, Ritardo: 0\n",
            "Numero: 77, Frequenza: 6, Ritardo: 0\n",
            "Numero: 40, Frequenza: 6, Ritardo: 4\n",
            "Numero: 41, Frequenza: 6, Ritardo: 11\n",
            "Numero: 30, Frequenza: 5, Ritardo: 1\n",
            "Numero: 63, Frequenza: 5, Ritardo: 2\n",
            "Numero: 83, Frequenza: 5, Ritardo: 2\n",
            "Numero: 11, Frequenza: 5, Ritardo: 3\n",
            "Numero: 85, Frequenza: 5, Ritardo: 6\n",
            "Numero: 48, Frequenza: 5, Ritardo: 15\n",
            "Numero: 19, Frequenza: 4, Ritardo: 0\n",
            "Numero: 21, Frequenza: 4, Ritardo: 0\n",
            "Numero: 74, Frequenza: 4, Ritardo: 0\n",
            "Numero: 49, Frequenza: 4, Ritardo: 1\n",
            "Numero: 89, Frequenza: 4, Ritardo: 1\n",
            "Numero: 31, Frequenza: 4, Ritardo: 2\n",
            "Numero: 86, Frequenza: 4, Ritardo: 2\n",
            "Numero: 7, Frequenza: 4, Ritardo: 3\n",
            "Numero: 10, Frequenza: 4, Ritardo: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALLENAMENTO"
      ],
      "metadata": {
        "id": "x5oP900ClZIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X contiene i numeri estratti come input (6 numeri)\n",
        "X = df.iloc[:-1, :6].values  # Numeri estratti (eliminando l'ultima riga)\n",
        "\n",
        "# y contiene i 6 numeri + Jolly + SuperStar come output (dalla seconda riga)\n",
        "y = df.iloc[1:, :8].values   # 6 numeri + Jolly + SuperStar (eliminando la prima riga)\n",
        "\n",
        "# Controlla le forme per essere sicuro che X e y abbiano la stessa lunghezza\n",
        "print(\"Forma di X:\", X.shape)\n",
        "print(\"Forma di y:\", y.shape)\n",
        "\n",
        "# Normalizzazione delle feature\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "\n",
        "scaler_y = StandardScaler()\n",
        "y_scaled = scaler_y.fit_transform(y)  # Normalizzazione separata per y\n",
        "\n",
        "# Modello di rete neurale\n",
        "model = Sequential([\n",
        "    Dense(128, input_dim=6, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(8, activation='linear')  # 6 numeri + Jolly + SuperStar\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Training\n",
        "model.fit(X_scaled, y_scaled, epochs=200, batch_size=10, verbose=1)\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX-RIH_3lXIX",
        "outputId": "382d584e-fc41-4c08-c1e0-37d2049e19c5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma di X: (39, 6)\n",
            "Forma di y: (39, 8)\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 1.0765 - mae: 0.8598  \n",
            "Epoch 2/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9457 - mae: 0.8095 \n",
            "Epoch 3/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0157 - mae: 0.8362 \n",
            "Epoch 4/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8777 - mae: 0.7917 \n",
            "Epoch 5/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8627 - mae: 0.7752 \n",
            "Epoch 6/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8791 - mae: 0.7882 \n",
            "Epoch 7/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8795 - mae: 0.7858 \n",
            "Epoch 8/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8855 - mae: 0.7859\n",
            "Epoch 9/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.9186 - mae: 0.8122\n",
            "Epoch 10/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7973 - mae: 0.7612 \n",
            "Epoch 11/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.9001 - mae: 0.7856 \n",
            "Epoch 12/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8567 - mae: 0.7647 \n",
            "Epoch 13/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.9113 - mae: 0.7987  \n",
            "Epoch 14/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8417 - mae: 0.7680 \n",
            "Epoch 15/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.7999 - mae: 0.7459 \n",
            "Epoch 16/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7532 - mae: 0.7332\n",
            "Epoch 17/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.7926 - mae: 0.7427\n",
            "Epoch 18/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7539 - mae: 0.7288\n",
            "Epoch 19/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7834 - mae: 0.7314\n",
            "Epoch 20/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7071 - mae: 0.7055 \n",
            "Epoch 21/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7954 - mae: 0.7470 \n",
            "Epoch 22/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7201 - mae: 0.7107 \n",
            "Epoch 23/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6628 - mae: 0.6842\n",
            "Epoch 24/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.7339 - mae: 0.7248\n",
            "Epoch 25/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6781 - mae: 0.6926\n",
            "Epoch 26/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6440 - mae: 0.6652\n",
            "Epoch 27/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6824 - mae: 0.6936\n",
            "Epoch 28/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.7061 - mae: 0.7005\n",
            "Epoch 29/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6197 - mae: 0.6604\n",
            "Epoch 30/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.6312 - mae: 0.6696 \n",
            "Epoch 31/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.6893 - mae: 0.6924 \n",
            "Epoch 32/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6021 - mae: 0.6448\n",
            "Epoch 33/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6023 - mae: 0.6507\n",
            "Epoch 34/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6477 - mae: 0.6657 \n",
            "Epoch 35/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6301 - mae: 0.6585 \n",
            "Epoch 36/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6259 - mae: 0.6514 \n",
            "Epoch 37/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5532 - mae: 0.6155 \n",
            "Epoch 38/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6344 - mae: 0.6479 \n",
            "Epoch 39/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.6000 - mae: 0.6387 \n",
            "Epoch 40/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.5829 - mae: 0.6344 \n",
            "Epoch 41/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5623 - mae: 0.6240 \n",
            "Epoch 42/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5845 - mae: 0.6360\n",
            "Epoch 43/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5554 - mae: 0.6224  \n",
            "Epoch 44/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4966 - mae: 0.5794 \n",
            "Epoch 45/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5150 - mae: 0.5936 \n",
            "Epoch 46/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5229 - mae: 0.5905 \n",
            "Epoch 47/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5574 - mae: 0.6112 \n",
            "Epoch 48/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.5346 - mae: 0.5944\n",
            "Epoch 49/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4642 - mae: 0.5693 \n",
            "Epoch 50/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5360 - mae: 0.5923 \n",
            "Epoch 51/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4540 - mae: 0.5671 \n",
            "Epoch 52/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4617 - mae: 0.5653\n",
            "Epoch 53/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5009 - mae: 0.5698 \n",
            "Epoch 54/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4914 - mae: 0.5722 \n",
            "Epoch 55/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4705 - mae: 0.5667 \n",
            "Epoch 56/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4538 - mae: 0.5577 \n",
            "Epoch 57/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4784 - mae: 0.5586 \n",
            "Epoch 58/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4097 - mae: 0.5189 \n",
            "Epoch 59/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4988 - mae: 0.5728\n",
            "Epoch 60/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4698 - mae: 0.5604 \n",
            "Epoch 61/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3703 - mae: 0.5090 \n",
            "Epoch 62/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4466 - mae: 0.5506 \n",
            "Epoch 63/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4373 - mae: 0.5404 \n",
            "Epoch 64/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3842 - mae: 0.5101 \n",
            "Epoch 65/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4171 - mae: 0.5313 \n",
            "Epoch 66/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.4098 - mae: 0.5298\n",
            "Epoch 67/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4023 - mae: 0.5212\n",
            "Epoch 68/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3587 - mae: 0.4958 \n",
            "Epoch 69/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3739 - mae: 0.5028 \n",
            "Epoch 70/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3602 - mae: 0.4913\n",
            "Epoch 71/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3496 - mae: 0.4777 \n",
            "Epoch 72/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3444 - mae: 0.4709 \n",
            "Epoch 73/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3135 - mae: 0.4640 \n",
            "Epoch 74/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3524 - mae: 0.4823 \n",
            "Epoch 75/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3214 - mae: 0.4618 \n",
            "Epoch 76/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3283 - mae: 0.4745 \n",
            "Epoch 77/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3169 - mae: 0.4662 \n",
            "Epoch 78/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3267 - mae: 0.4754 \n",
            "Epoch 79/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3144 - mae: 0.4690 \n",
            "Epoch 80/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3123 - mae: 0.4591 \n",
            "Epoch 81/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3010 - mae: 0.4543 \n",
            "Epoch 82/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2946 - mae: 0.4491 \n",
            "Epoch 83/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2978 - mae: 0.4533 \n",
            "Epoch 84/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3295 - mae: 0.4746 \n",
            "Epoch 85/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2965 - mae: 0.4477 \n",
            "Epoch 86/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2539 - mae: 0.4130 \n",
            "Epoch 87/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2701 - mae: 0.4212 \n",
            "Epoch 88/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2687 - mae: 0.4305 \n",
            "Epoch 89/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2484 - mae: 0.4116 \n",
            "Epoch 90/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2649 - mae: 0.4253 \n",
            "Epoch 91/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2591 - mae: 0.4189 \n",
            "Epoch 92/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2542 - mae: 0.4158 \n",
            "Epoch 93/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2792 - mae: 0.4349 \n",
            "Epoch 94/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2418 - mae: 0.4034 \n",
            "Epoch 95/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2448 - mae: 0.4090 \n",
            "Epoch 96/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2468 - mae: 0.4016 \n",
            "Epoch 97/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2210 - mae: 0.3806 \n",
            "Epoch 98/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2463 - mae: 0.4058 \n",
            "Epoch 99/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2197 - mae: 0.3781 \n",
            "Epoch 100/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2160 - mae: 0.3779 \n",
            "Epoch 101/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1997 - mae: 0.3691 \n",
            "Epoch 102/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2240 - mae: 0.3847 \n",
            "Epoch 103/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1980 - mae: 0.3581 \n",
            "Epoch 104/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2017 - mae: 0.3651 \n",
            "Epoch 105/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1853 - mae: 0.3478\n",
            "Epoch 106/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1802 - mae: 0.3407 \n",
            "Epoch 107/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2205 - mae: 0.3841 \n",
            "Epoch 108/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1954 - mae: 0.3567 \n",
            "Epoch 109/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2018 - mae: 0.3626 \n",
            "Epoch 110/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2219 - mae: 0.3852 \n",
            "Epoch 111/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1986 - mae: 0.3563 \n",
            "Epoch 112/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1898 - mae: 0.3549 \n",
            "Epoch 113/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1640 - mae: 0.3243\n",
            "Epoch 114/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1694 - mae: 0.3313 \n",
            "Epoch 115/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1659 - mae: 0.3286 \n",
            "Epoch 116/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1869 - mae: 0.3420 \n",
            "Epoch 117/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1690 - mae: 0.3251 \n",
            "Epoch 118/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1813 - mae: 0.3373 \n",
            "Epoch 119/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1691 - mae: 0.3268\n",
            "Epoch 120/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1589 - mae: 0.3196  \n",
            "Epoch 121/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1656 - mae: 0.3239 \n",
            "Epoch 122/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1478 - mae: 0.3070\n",
            "Epoch 123/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1509 - mae: 0.3090\n",
            "Epoch 124/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1489 - mae: 0.3044 \n",
            "Epoch 125/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1472 - mae: 0.3010 \n",
            "Epoch 126/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1402 - mae: 0.2896\n",
            "Epoch 127/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1422 - mae: 0.2989 \n",
            "Epoch 128/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1425 - mae: 0.2976 \n",
            "Epoch 129/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1437 - mae: 0.2978 \n",
            "Epoch 130/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1384 - mae: 0.2950 \n",
            "Epoch 131/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1486 - mae: 0.2984 \n",
            "Epoch 132/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1483 - mae: 0.2997 \n",
            "Epoch 133/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1217 - mae: 0.2702 \n",
            "Epoch 134/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1449 - mae: 0.3040 \n",
            "Epoch 135/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1284 - mae: 0.2760 \n",
            "Epoch 136/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1463 - mae: 0.2966 \n",
            "Epoch 137/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1239 - mae: 0.2759 \n",
            "Epoch 138/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1197 - mae: 0.2658 \n",
            "Epoch 139/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1359 - mae: 0.2794 \n",
            "Epoch 140/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0986 - mae: 0.2436 \n",
            "Epoch 141/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1199 - mae: 0.2664 \n",
            "Epoch 142/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1098 - mae: 0.2532 \n",
            "Epoch 143/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1042 - mae: 0.2492 \n",
            "Epoch 144/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1179 - mae: 0.2589 \n",
            "Epoch 145/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0953 - mae: 0.2394 \n",
            "Epoch 146/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1099 - mae: 0.2585 \n",
            "Epoch 147/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1266 - mae: 0.2721 \n",
            "Epoch 148/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1143 - mae: 0.2618 \n",
            "Epoch 149/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1141 - mae: 0.2554 \n",
            "Epoch 150/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0974 - mae: 0.2422 \n",
            "Epoch 151/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1008 - mae: 0.2462 \n",
            "Epoch 152/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0976 - mae: 0.2326\n",
            "Epoch 153/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0956 - mae: 0.2343 \n",
            "Epoch 154/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1130 - mae: 0.2570 \n",
            "Epoch 155/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0917 - mae: 0.2286 \n",
            "Epoch 156/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.1020 - mae: 0.2391\n",
            "Epoch 157/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0906 - mae: 0.2281 \n",
            "Epoch 158/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0994 - mae: 0.2346 \n",
            "Epoch 159/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1074 - mae: 0.2457 \n",
            "Epoch 160/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0970 - mae: 0.2317 \n",
            "Epoch 161/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0760 - mae: 0.2021 \n",
            "Epoch 162/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0938 - mae: 0.2273 \n",
            "Epoch 163/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0955 - mae: 0.2288 \n",
            "Epoch 164/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0943 - mae: 0.2296 \n",
            "Epoch 165/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0742 - mae: 0.2020 \n",
            "Epoch 166/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0942 - mae: 0.2281 \n",
            "Epoch 167/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0756 - mae: 0.2029 \n",
            "Epoch 168/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0992 - mae: 0.2353 \n",
            "Epoch 169/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0794 - mae: 0.2091\n",
            "Epoch 170/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0714 - mae: 0.1959 \n",
            "Epoch 171/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0736 - mae: 0.1989 \n",
            "Epoch 172/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1005 - mae: 0.2334 \n",
            "Epoch 173/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0952 - mae: 0.2259 \n",
            "Epoch 174/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0902 - mae: 0.2240\n",
            "Epoch 175/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0736 - mae: 0.2004 \n",
            "Epoch 176/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0790 - mae: 0.2067 \n",
            "Epoch 177/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0815 - mae: 0.2074 \n",
            "Epoch 178/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0862 - mae: 0.2102 \n",
            "Epoch 179/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0651 - mae: 0.1868 \n",
            "Epoch 180/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0803 - mae: 0.2064 \n",
            "Epoch 181/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0765 - mae: 0.2032 \n",
            "Epoch 182/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0767 - mae: 0.2010 \n",
            "Epoch 183/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0721 - mae: 0.1977 \n",
            "Epoch 184/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0812 - mae: 0.2037\n",
            "Epoch 185/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0734 - mae: 0.1970\n",
            "Epoch 186/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0716 - mae: 0.1919 \n",
            "Epoch 187/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0769 - mae: 0.1995 \n",
            "Epoch 188/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0734 - mae: 0.1915\n",
            "Epoch 189/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0781 - mae: 0.2037 \n",
            "Epoch 190/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0819 - mae: 0.2097 \n",
            "Epoch 191/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0804 - mae: 0.2061 \n",
            "Epoch 192/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0703 - mae: 0.1868 \n",
            "Epoch 193/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0644 - mae: 0.1777 \n",
            "Epoch 194/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0621 - mae: 0.1755 \n",
            "Epoch 195/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0650 - mae: 0.1808 \n",
            "Epoch 196/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0657 - mae: 0.1819 \n",
            "Epoch 197/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0729 - mae: 0.1947 \n",
            "Epoch 198/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0561 - mae: 0.1699\n",
            "Epoch 199/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0540 - mae: 0.1681\n",
            "Epoch 200/200\n",
            "\u001b[1m4/4\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0711 - mae: 0.1956\n",
            "Shape of X: (39, 6)\n",
            "Shape of y: (39, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREVISIONI"
      ],
      "metadata": {
        "id": "FwyzkUHbmit9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsione sulla prossima estrazione\n",
        "# L'ultima estrazione di numeri (X) che utilizzeremo come input\n",
        "last_entry = df.iloc[-1, :6].values.reshape(1, -1)  # Reshape per essere compatibile con il modello\n",
        "\n",
        "# Normalizzazione dell'ultima estrazione (usando lo scaler giÃ  creato)\n",
        "last_entry_scaled = scaler_X.transform(last_entry)\n",
        "\n",
        "# Previsione con il modello\n",
        "prediction_scaled = model.predict(last_entry_scaled)\n",
        "\n",
        "# Invertiamo la normalizzazione per ottenere i numeri reali\n",
        "prediction = scaler_y.inverse_transform(prediction_scaled)\n",
        "\n",
        "# Estraiamo i numeri previsti\n",
        "predicted_numbers = np.round(prediction[0][:6]).astype(int)  # I 6 numeri principali\n",
        "predicted_jolly = int(np.round(prediction[0][6]))  # Jolly\n",
        "predicted_superstar = int(np.round(prediction[0][7]))  # SuperStar\n",
        "\n",
        "# Stampa la previsione\n",
        "print(\"ð® Previsione per la prossima estrazione:\")\n",
        "print(f\"ð° Numeri: {predicted_numbers}\")\n",
        "print(f\"ð Jolly previsto: {predicted_jolly}\")\n",
        "print(f\"ð SuperStar previsto: {predicted_superstar}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bttp-ghZmkQ9",
        "outputId": "39fde5fc-d8c4-4e6c-86d7-fa19510c67db"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "ð® Previsione per la prossima estrazione:\n",
            "ð° Numeri: [ 9 18 24 31 48 60]\n",
            "ð Jolly previsto: 42\n",
            "ð SuperStar previsto: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizza i dati e fai previsioni"
      ],
      "metadata": {
        "id": "PDspqtCQgoqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#nooo\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Carica il file ZIP\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Verifica il nome del file caricato\n",
        "file_name = list(uploaded.keys())[0]\n",
        "zip_path = f'/content/{file_name}'\n",
        "\n",
        "# Estrai il contenuto del file ZIP\n",
        "extracted_folder = '/content/extracted/'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_folder)\n",
        "\n",
        "# Verifica i file estratti\n",
        "extracted_files = os.listdir(extracted_folder)\n",
        "print(f\"File estratti: {extracted_files}\")\n",
        "\n",
        "# Salva il path del file Excel estratto per usarlo nella seconda cella\n",
        "excel_file_path = os.path.join(extracted_folder, extracted_files[0])\n",
        "print(f\"File Excel estratto: {excel_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ste5YD1_IghP",
        "outputId": "0087f942-792e-4191-ca5e-91a78c4c4503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7d3f567d-e2b4-440f-980a-3a932fa06739\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7d3f567d-e2b4-440f-980a-3a932fa06739\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ea98259b2b54>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Carica il file ZIP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Verifica il nome del file caricato\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Usa il path ottenuto dalla prima cella\n",
        "file_path = '/content/extracted/it-superenalotto-past-draws-archive.xls'  # Assicurati che questo percorso sia corretto\n",
        "\n",
        "def carica_database(file_path):\n",
        "    # Usa 'xlrd' come engine per i file .xls\n",
        "    df = pd.read_excel(file_path, engine='xlrd', skiprows=1)\n",
        "    numeri_estratti = df.select_dtypes(include='number').dropna(axis=1, how='all')\n",
        "    numeri_estratti = numeri_estratti.tail(500)\n",
        "    return numeri_estratti\n",
        "\n",
        "# Carica i dati nel DataFrame\n",
        "df = carica_database(file_path)\n",
        "\n",
        "# Visualizza le prime 10 righe\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "id": "Sia9c1rtLRf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codice per ordinare e correggere i dati:"
      ],
      "metadata": {
        "id": "NMlAQ3KPZJCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pulizia dei dati: rimuoviamo le colonne vuote e manteniamo solo i numeri\n",
        "def pulizia_dati(df):\n",
        "    df_cleaned = df.select_dtypes(include='number').dropna(axis=1, how='all')  # Manteniamo solo colonne con numeri\n",
        "    return df_cleaned\n",
        "\n",
        "# Applichiamo la pulizia\n",
        "df_cleaned = pulizia_dati(df)\n",
        "\n",
        "# Mostra le prime 10 righe dopo la pulizia\n",
        "print(df_cleaned.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxPxAV8QMQ-R",
        "outputId": "10e14dc3-3add-4ae2-978a-a150eb305bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
            "0         NaN         NaN         NaN         NaN         NaN\n",
            "1         NaN         NaN         NaN         NaN         NaN\n",
            "2         2.0         3.0         4.0         5.0         6.0\n",
            "3        16.0        35.0        59.0        65.0        87.0\n",
            "4        24.0        25.0        30.0        43.0        47.0\n",
            "5        10.0        18.0        19.0        32.0        36.0\n",
            "6        28.0        52.0        63.0        77.0        79.0\n",
            "7        12.0        33.0        40.0        41.0        83.0\n",
            "8        12.0        37.0        59.0        63.0        90.0\n",
            "9        31.0        33.0        42.0        51.0        72.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j1VxXlRJTKfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seleziona solo le colonne numeriche (i numeri estratti)"
      ],
      "metadata": {
        "id": "u9YJhjwgQaKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleziona solo le colonne numeriche (i numeri estratti)\n",
        "df_cleaned = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Rimuove righe che contengono tutti valori NaN\n",
        "df_cleaned = df_cleaned.dropna(how='all')\n",
        "\n",
        "# Converte i numeri in interi per eliminare i .0\n",
        "df_cleaned = df_cleaned.astype(int)\n",
        "\n",
        "# Stampa i primi numeri per verificare\n",
        "print(df_cleaned.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0IdgeqrQdWw",
        "outputId": "9f5f67bc-5f48-4cb9-f952-422a1634aef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7\n",
            "2            2           3           4           5           6\n",
            "3           16          35          59          65          87\n",
            "4           24          25          30          43          47\n",
            "5           10          18          19          32          36\n",
            "6           28          52          63          77          79\n",
            "7           12          33          40          41          83\n",
            "8           12          37          59          63          90\n",
            "9           31          33          42          51          72\n",
            "10          58          68          83          89          90\n",
            "11          40          48          49          52          89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Prendi solo le ultime 500 estrazioni"
      ],
      "metadata": {
        "id": "u8ej44cHQf5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df_cleaned.tail(800)"
      ],
      "metadata": {
        "id": "PpUAkVMoQidR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizza i dati tra 0 e 1"
      ],
      "metadata": {
        "id": "7RBwT-sAQlOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df_scaled = scaler.fit_transform(df_cleaned)\n"
      ],
      "metadata": {
        "id": "1CxlovdwQnkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Funzione per creare sequenze di dati"
      ],
      "metadata": {
        "id": "qIcfZ0ahQqEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepara_dati(df_scaled, sequenza_lunghezza=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df_scaled) - sequenza_lunghezza):\n",
        "        X.append(df_scaled[i:i + sequenza_lunghezza])\n",
        "        y.append(df_scaled[i + sequenza_lunghezza])  # Previsione successiva\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "qUGFetRWQshw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepara i dati per il modello LSTM"
      ],
      "metadata": {
        "id": "lo11sdSHQxhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepara_dati(df_scaled, sequenza_lunghezza=5):\n",
        "    X, y = [], []\n",
        "    for i in range(len(df_scaled) - sequenza_lunghezza):  # Modifica qui\n",
        "        X.append(df_scaled[i:i + sequenza_lunghezza])  # Aggiungi sequenza di lunghezza 5\n",
        "        y.append(df_scaled[i + sequenza_lunghezza])  # Previsione successiva\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "rpyJ3pyiQyzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creiamo il modello LSTM e lo alleniamo"
      ],
      "metadata": {
        "id": "jn9uXI9hQ2gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepara i dati\n",
        "X, y = prepara_dati(df_scaled)\n",
        "\n",
        "# Dividi i dati in set di training e testing\n",
        "split_index = int(len(X) * 0.8)  # Usa l'80% per il training\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]\n",
        "\n",
        "# Crea il modello LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=y_train.shape[1]))  # Output layer con numero di unitÃ  pari a features\n",
        "\n",
        "# Compila il modello\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Allena il modello\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)  #epochs=50, batch_size=32\n",
        "\n",
        "# Valuta il modello\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Loss sul set di test: {loss}\")\n",
        "\n",
        "# Fai delle previsioni\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Inverti la normalizzazione per ottenere le previsioni nella scala originale\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "\n",
        "# Stampa le prime 10 previsioni\n",
        "print(\"Prime 10 previsioni:\")\n",
        "print(predictions[:10])\n",
        "\n",
        "# Stampa le prime 10 osservazioni reali\n",
        "print(\"\\nPrime 10 osservazioni reali:\")\n",
        "print(y_test[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UNX6AoNeB0z",
        "outputId": "9f97fffc-b6d1-422d-e77f-d4b29a0a16f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 0.4807\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.4516\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.4218\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.3953\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.3680\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.3451\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.3193\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2940\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.2633\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.2390\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.2281\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1894\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.1677\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.1382\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.1136\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0992\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0898\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0681\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0700\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0802\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0827\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0779\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0843\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0868\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0697\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0668\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0731\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0698\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0600\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0785\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0583\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0582\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0589\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0667\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0577\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0660\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0663\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0609\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0633\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0677\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0575\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0626\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0582\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0562\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0580\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0617\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0608\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0583\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0648\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0577\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0582\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0572\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0532\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0579\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0543\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0590\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0583\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0528\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0511\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0605\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0601\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0571\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0473\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0605\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0589\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0615\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0642\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0636\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0422\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0512\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0470\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0684\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0572\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0548\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0587\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0631\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0565\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0628\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0566\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0498\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0486\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0544\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0617\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0531\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0579\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0643\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0522\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0462\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0571\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0500\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0479\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0602\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0512\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0433\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0543\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0547\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0512\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0592\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0577\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470ms/step - loss: 0.0443\n",
            "Loss sul set di test: 0.044313836842775345\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "Prime 10 previsioni:\n",
            "[[27.233118 38.502842 54.945553 61.17108  76.00749 ]\n",
            " [26.930758 37.98834  54.169174 60.46741  74.58042 ]\n",
            " [27.722692 39.028976 55.790695 62.672565 77.085304]\n",
            " [27.148346 38.621914 55.72934  62.79154  77.502556]\n",
            " [26.579315 36.97986  53.237617 59.694862 73.28127 ]\n",
            " [26.725012 37.48579  54.510834 61.19739  75.286674]\n",
            " [27.453188 39.418995 57.27091  64.317764 79.645035]]\n",
            "\n",
            "Prime 10 osservazioni reali:\n",
            "[[ 6. 11. 22. 35. 85.]\n",
            " [25. 33. 49. 57. 72.]\n",
            " [33. 40. 71. 74. 82.]\n",
            " [10. 11. 29. 32. 87.]\n",
            " [42. 43. 63. 83. 86.]\n",
            " [30. 43. 49. 74. 89.]\n",
            " [21. 29. 74. 77. 88.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ottimizzazione del modello mix tra dati statistici e training"
      ],
      "metadata": {
        "id": "Qd14gmUAfddP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Funzione per calcolare la similaritÃ  tra la previsione e l'estrazione\n",
        "def calcola_similarita(previsione, estrazione):\n",
        "    return len(set(previsione) & set(estrazione))\n",
        "\n",
        "# Funzione per testare diverse combinazioni di pesi\n",
        "def ottimizza_pesi(previsione_ml, top_frequenti, ritardatari, estrazioni_reali):\n",
        "    best_weight_model = 0\n",
        "    best_weight_stat = 0\n",
        "    best_precision = 0\n",
        "\n",
        "    # Prova diverse combinazioni di pesi (grid search)\n",
        "    for weight_model in np.arange(0, 1.1, 0.1):\n",
        "        for weight_stat in np.arange(0, 1.1, 0.1):\n",
        "            if weight_model + weight_stat > 1:  # La somma dei pesi non deve superare 1\n",
        "                continue\n",
        "\n",
        "            previsione_combinata = []\n",
        "\n",
        "            # Aggiungi le previsioni del modello ponderate\n",
        "            for num in previsione_ml:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Aggiungi i numeri frequenti ponderati\n",
        "            for num in top_frequenti:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Aggiungi i numeri ritardatari ponderati\n",
        "            for num in ritardatari[:3]:\n",
        "                if num not in previsione_combinata and len(previsione_combinata) < 6:\n",
        "                    previsione_combinata.append(num)\n",
        "\n",
        "            # Se non raggiungi 6 numeri, aggiungi casualmente\n",
        "            while len(previsione_combinata) < 6:\n",
        "                random_number = np.random.choice(ritardatari)  # Aggiungi un numero ritardatario casuale\n",
        "                if random_number not in previsione_combinata:\n",
        "                    previsione_combinata.append(random_number)\n",
        "\n",
        "            # Calcola la similaritÃ  tra la previsione e le estrazioni reali\n",
        "            total_similarity = 0\n",
        "            for estrazione in estrazioni_reali:\n",
        "                total_similarity += calcola_similarita(previsione_combinata, estrazione)\n",
        "\n",
        "            # Calcola la precisione media\n",
        "            precisione = total_similarity / len(estrazioni_reali)\n",
        "\n",
        "            # Aggiorna la miglior combinazione di pesi\n",
        "            if precisione > best_precision:\n",
        "                best_precision = precisione\n",
        "                best_weight_model = weight_model\n",
        "                best_weight_stat = weight_stat\n",
        "\n",
        "    return best_weight_model, best_weight_stat, best_precision\n",
        "\n",
        "\n",
        "# Test su un sottoinsieme di estrazioni reali (ultime 50 estrazioni)\n",
        "estrazioni_reali = df.tail(50).values.tolist()  # Usa le ultime 50 estrazioni\n",
        "\n",
        "# Ottimizzazione dei pesi\n",
        "best_weight_model, best_weight_stat, best_precision = ottimizza_pesi(\n",
        "    predictions[-1].astype(int),  # Predizioni del modello\n",
        "    [num for num, freq in numeri_ordinati_frequenza[:5]],  # Top 5 numeri frequenti\n",
        "    ritardatari,  # Numeri ritardatari\n",
        "    estrazioni_reali\n",
        ")\n",
        "\n",
        "print(f\"\\nMigliori pesi trovati: modello={best_weight_model}, statistica={best_weight_stat}\")\n",
        "print(f\"Precisione media ottenuta: {best_precision:.2f}\")\n",
        "\n",
        "# Previsione finale con i pesi ottimizzati\n",
        "previsione_combinata_ottimizzata = []\n",
        "\n",
        "# Aggiungi le previsioni del modello ponderate\n",
        "for num in predictions[-1].astype(int):\n",
        "    if num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Aggiungi i numeri piÃ¹ frequenti ponderati\n",
        "for num in numeri_ordinati_frequenza[:5]:\n",
        "    if num[0] not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num[0])\n",
        "\n",
        "# Aggiungi i numeri ritardatari ponderati\n",
        "for num in ritardatari[:3]:\n",
        "    if num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Se non raggiungi 6 numeri, prendi numeri casuali dai ritardatari\n",
        "while len(previsione_combinata_ottimizzata) < 6:\n",
        "    random_number = np.random.choice(ritardatari)  # Aggiungi un numero ritardatario casuale\n",
        "    if random_number not in previsione_combinata_ottimizzata:\n",
        "        previsione_combinata_ottimizzata.append(random_number)\n",
        "\n",
        "# Stampa la previsione finale ottimizzata\n",
        "print(f\"\\nPrevisione finale ottimizzata: {previsione_combinata_ottimizzata}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU0m89s0hjKG",
        "outputId": "03d593c4-151d-4b2e-e659-21803362f92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migliori pesi trovati: modello=0.0, statistica=0.0\n",
            "Precisione media ottenuta: 0.57\n",
            "\n",
            "Previsione finale ottimizzata: [10, 18, 15, 31, 72.0, 40.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsione finale ottimizzata: senza duplicati e con numeri interi\n",
        "previsione_combinata_ottimizzata = []\n",
        "\n",
        "# Aggiungi la percentuale di ottimizzazione\n",
        "percentuale_model = peso_model_ottimizzato * 100  # Pesi ottimizzati per il modello, espressi come percentuali\n",
        "percentuale_stat = peso_stat_ottimizzato * 100  # Pesi ottimizzati per la statistica, espressi come percentuali\n",
        "\n",
        "# Prendi l'ultima estrazione\n",
        "ultima_estrazione = df_cleaned.tail(1).values.flatten()  # Consideriamo l'ultima estrazione, se necessario puoi regolare questo\n",
        "\n",
        "# Aggiungi le previsioni ponderate (senza duplicati)\n",
        "previsione_combinata_ottimizzata.extend([int(num) for num in predictions[-1].astype(int)[:int(6 * peso_model_ottimizzato)]])\n",
        "\n",
        "# Aggiungi i numeri frequenti ponderati (senza duplicati)\n",
        "previsione_combinata_ottimizzata.extend([num for num, _ in numeri_ordinati_frequenza[:int(6 * peso_stat_ottimizzato)]])\n",
        "\n",
        "# Aggiungi numeri ritardatari se necessario (senza duplicati)\n",
        "for num in ritardatari[:3]:\n",
        "    # Check if num is not NaN before appending\n",
        "    if not pd.isnull(num) and num not in previsione_combinata_ottimizzata and len(previsione_combinata_ottimizzata) < 6:\n",
        "        previsione_combinata_ottimizzata.append(num)\n",
        "\n",
        "# Elimina duplicati dalla previsione finale\n",
        "previsione_combinata_ottimizzata = list(set(previsione_combinata_ottimizzata))\n",
        "\n",
        "# Rimuovi i numeri che sono giÃ  usciti nell'ultima estrazione\n",
        "previsione_combinata_ottimizzata = [num for num in previsione_combinata_ottimizzata if num not in ultima_estrazione]\n",
        "\n",
        "# Se ci sono meno di 6 numeri, aggiungi numeri mancanti dalla lista dei numeri ritardatari\n",
        "while len(previsione_combinata_ottimizzata) < 6:\n",
        "    for rit in ritardatari:\n",
        "        # Check if rit is not NaN before appending\n",
        "        if not pd.isnull(rit) and rit not in previsione_combinata_ottimizzata:\n",
        "            previsione_combinata_ottimizzata.append(rit)\n",
        "        if len(previsione_combinata_ottimizzata) == 6:\n",
        "            break\n",
        "\n",
        "# Convertili tutti in interi\n",
        "previsione_combinata_ottimizzata = [int(num) for num in previsione_combinata_ottimizzata]\n",
        "\n",
        "# Stampa la previsione finale con la percentuale di ottimizzazione\n",
        "print(f\"\\nPrevisione finale ottimizzata:\")\n",
        "print(f\"Numeri previsti: {previsione_combinata_ottimizzata}\")\n",
        "print(f\"Percentuale ottimizzata per il modello: {percentuale_model:.2f}%\")\n",
        "print(f\"Percentuale ottimizzata per la statistica: {percentuale_stat:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWVIgjN3iIoJ",
        "outputId": "122fc18c-d9d3-49fc-8ef5-1a6dcce5185d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Previsione finale ottimizzata:\n",
            "Numeri previsti: [72, 40, 10, 41, 18, 2]\n",
            "Percentuale ottimizzata per il modello: 50.00%\n",
            "Percentuale ottimizzata per la statistica: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previsione e salvataggio in CSV"
      ],
      "metadata": {
        "id": "vN5JOXpoQ9EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "ultima_sequenza = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
        "predizione = modello.predict(ultima_sequenza)\n",
        "\n",
        "# Denormalizza la predizione per riportare i valori tra 1 e 90\n",
        "predizione_denorm = scaler.inverse_transform(predizione)\n",
        "\n",
        "# Arrotonda e limita i valori tra 1 e 90\n",
        "def trasforma_predizione(predizione_denorm):\n",
        "    predizione_arrotondata = np.round(predizione_denorm).astype(int)  # Arrotonda e converte in int\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Assicura i numeri validi\n",
        "    return predizione_arrotondata\n",
        "\n",
        "# Applica la trasformazione\n",
        "predizione_interi = trasforma_predizione(predizione_denorm)\n",
        "\n",
        "# Controllo prima di salvare\n",
        "print(f\"Predizione della prossima estrazione: {predizione_interi.flatten()}\")\n",
        "\n",
        "# Creazione del DataFrame con il formato corretto\n",
        "df_predizione = pd.DataFrame(predizione_interi, columns=[\"Num1\", \"Num2\", \"Num3\", \"Num4\", \"Num5\"])\n",
        "\n",
        "# Salvataggio corretto in CSV\n",
        "csv_path = \"/content/prossima_estrazione.csv\"\n",
        "df_predizione.to_csv(csv_path, index=False, header=True)\n",
        "\n",
        "print(f\"File CSV salvato correttamente in {csv_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUs7OtVPQ_ks",
        "outputId": "fb5595d1-c08b-44c8-f8af-ad662dbe34f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step\n",
            "Predizione della prossima estrazione: [1 1 1 1 1]\n",
            "File CSV salvato correttamente in /content/prossima_estrazione.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-0635bc2e6773>:13: RuntimeWarning: invalid value encountered in cast\n",
            "  predizione_arrotondata = np.round(predizione_denorm).astype(int)  # Arrotonda e converte in int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import zipfile\n",
        "\n",
        "file_path = '/content/it-superenalotto-past-draws-archive.zip'\n",
        "\n",
        "def carica_database(file_path):\n",
        "    # Estrai il file .xls dal file .zip\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        xls_file = zip_ref.namelist()[0]  # Ottieni il nome del file .xls all'interno dello zip\n",
        "        with zip_ref.open(xls_file) as file:\n",
        "            # Leggi il file Excel usando il file estratto\n",
        "            df = pd.read_excel(file, engine='xlrd', skiprows=1)\n",
        "    # Prende solo numeri e rimuove colonne vuote\n",
        "    numeri_estratti = df.select_dtypes(include='number').dropna(axis=1, how='all')\n",
        "\n",
        "    # Usa solo le ultime 50 estrazioni ð¥\n",
        "    numeri_estratti = numeri_estratti.tail(50)\n",
        "    return numeri_estratti\n",
        "\n",
        "def calcola_frequenze(df):\n",
        "    frequenze = df.stack().value_counts()\n",
        "    return frequenze.head(5).index.tolist()\n",
        "\n",
        "def calcola_ritardatari(df):\n",
        "    numeri_totali = set(range(1, 91))\n",
        "    ultime_uscite = {}\n",
        "\n",
        "    for numero in numeri_totali:\n",
        "        try:\n",
        "            ultima_pos = df.apply(lambda colonna: numero in colonna.values).iloc[::-1].idxmax()\n",
        "            ultime_uscite[numero] = ultima_pos\n",
        "        except:\n",
        "            ultime_uscite[numero] = -1\n",
        "\n",
        "    ritardatari = sorted(ultime_uscite, key=ultime_uscite.get, reverse=True)[:5]\n",
        "    return ritardatari\n",
        "\n",
        "def somma_90(previsione):\n",
        "    somma = (previsione[0] + previsione[1]) % 90\n",
        "    if somma == 0:\n",
        "        somma = 90\n",
        "    return somma\n",
        "\n",
        "# Esegui tutto\n",
        "df = carica_database(file_path)\n",
        "numeri_frequenti = calcola_frequenze(df)\n",
        "numeri_ritardatari = calcola_ritardatari(df)\n",
        "previsione = numeri_frequenti + numeri_ritardatari\n",
        "somma = somma_90(previsione)\n",
        "\n",
        "print(f\"Data aggiornamento: {datetime.date.today()}\")\n",
        "print(\"Numeri piÃ¹ frequenti:\", numeri_frequenti)\n",
        "print(\"Numeri ritardatari:\", numeri_ritardatari)\n",
        "print(\"Previsione Finale:\", previsione)\n",
        "print(\"ð¥ Somma 90:\", somma)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOqNKLh13XVe",
        "outputId": "e7619a0f-12bb-4829-d8c9-62109e8ee3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
            "Data aggiornamento: 2025-03-10\n",
            "Numeri piÃ¹ frequenti: [72.0, 77.0, 40.0, 41.0, 85.0]\n",
            "Numeri ritardatari: [1, 6, 8, 9, 13]\n",
            "Previsione Finale: [72.0, 77.0, 40.0, 41.0, 85.0, 1, 6, 8, 9, 13]\n",
            "ð¥ Somma 90: 59.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1KGV-7aJYOu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previsione Finale\n"
      ],
      "metadata": {
        "id": "ke-VWxBXV-Dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Caricamento delle ultime 10 estrazioni\n",
        "file_path = '/content/it-superenalotto-past-draws-archive.zip'\n",
        "df = carica_database(file_path)  # Funzione che abbiamo giÃ  definito\n",
        "ultime_estrazioni = df.tail(200).values  # Prendiamo solo i valori numerici\n",
        "\n",
        "# Previsioni ottenute\n",
        "previsione_ml = [26, 36, 57, 70, 90]  # Sostituisci con la tua previsione ML\n",
        "top_numeri_stat = [72, 41, 40, 77, 83, 1, 6, 8, 9, 13]  # Previsione statistica\n",
        "\n",
        "# Funzione per contare i match tra previsione e ultime estrazioni\n",
        "def conta_match(previsione, estrazioni):\n",
        "    match_per_estrazione = [len(set(previsione) & set(estr)) for estr in estrazioni]\n",
        "    totale_match = sum(match_per_estrazione)\n",
        "    return totale_match, match_per_estrazione\n",
        "\n",
        "# Confronto tra previsioni e ultime estrazioni\n",
        "match_ml, dettagli_ml = conta_match(previsione_ml, ultime_estrazioni)\n",
        "match_stat, dettagli_stat = conta_match(top_numeri_stat, ultime_estrazioni)\n",
        "\n",
        "# Analisi frequenze\n",
        "frequenze = df.stack().value_counts().head(15)  # Prendi i 15 numeri piÃ¹ frequenti\n",
        "\n",
        "# Output risultati\n",
        "print(f\"ð¯ Confronto con le ultime 10 estrazioni:\")\n",
        "print(f\"âï¸ Match con ML: {match_ml} numeri trovati\")\n",
        "print(f\"âï¸ Match con Statistica: {match_stat} numeri trovati\")\n",
        "print(\"\\nð Dettaglio delle corrispondenze per ogni estrazione:\")\n",
        "print(f\"ML: {dettagli_ml}\")\n",
        "print(f\"Statistica: {dettagli_stat}\")\n",
        "print(\"\\nð¥ Numeri piÃ¹ frequenti nelle ultime estrazioni:\")\n",
        "print(frequenze)\n",
        "\n",
        "# Suggerimento per la prossima previsione\n",
        "suggeriti = set(frequenze.index[:5]) | set(top_numeri_stat[:5])  # Unione dei top numeri\n",
        "print(\"\\nð Numeri suggeriti per la prossima estrazione:\")\n",
        "print(suggeriti)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAB4A51zV_7O",
        "outputId": "d82b9102-74f5-4d00-edb4-c10ee0c081a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
            "ð¯ Confronto con le ultime 10 estrazioni:\n",
            "âï¸ Match con ML: 7 numeri trovati\n",
            "âï¸ Match con Statistica: 35 numeri trovati\n",
            "\n",
            "ð Dettaglio delle corrispondenze per ogni estrazione:\n",
            "ML: [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "Statistica: [0, 0, 1, 0, 0, 0, 1, 3, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 3, 3, 0, 1, 1, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
            "\n",
            "ð¥ Numeri piÃ¹ frequenti nelle ultime estrazioni:\n",
            "72.0    9\n",
            "77.0    6\n",
            "40.0    6\n",
            "41.0    6\n",
            "85.0    5\n",
            "63.0    5\n",
            "83.0    5\n",
            "30.0    5\n",
            "29.0    5\n",
            "59.0    4\n",
            "87.0    4\n",
            "25.0    4\n",
            "49.0    4\n",
            "74.0    4\n",
            "86.0    4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ð Numeri suggeriti per la prossima estrazione:\n",
            "{72.0, 41.0, 40.0, 77.0, 83, 85.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PTKiL26PWlVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Funzione migliorata per preparare i dati (controllo dei NaN)\n",
        "def prepara_dati(df_cleaned, sequenza_lenght=5):\n",
        "    sequenze = []\n",
        "    target = []\n",
        "\n",
        "    for i in range(len(df_cleaned) - sequenza_lenght):\n",
        "        # Estrazione dei numeri per la sequenza\n",
        "        sequenza = df_cleaned.iloc[i:i + sequenza_lenght].values.flatten()\n",
        "\n",
        "        # Se la sequenza contiene NaN, la scartiamo\n",
        "        if np.any(np.isnan(sequenza)):\n",
        "            continue\n",
        "\n",
        "        sequenze.append(sequenza)\n",
        "        target.append(df_cleaned.iloc[i + sequenza_lenght].values.flatten())\n",
        "\n",
        "    X = np.array(sequenze)\n",
        "    y = np.array(target)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Prepara i dati\n",
        "X, y = prepara_dati(df_cleaned)\n",
        "\n",
        "# Verifica la forma dei dati\n",
        "print(f\"Forma di X: {X.shape}\")\n",
        "print(f\"Forma di y: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkS8_GdaNEes",
        "outputId": "b7a38857-a486-4718-c238-e05bb0a71720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma di X: (33, 25)\n",
            "Forma di y: (33, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVpbyqlfMO5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terza Cella: Prepara i dati per l'allenamento"
      ],
      "metadata": {
        "id": "b9lin5HxYQ6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Funzione per preparare i dati: crea sequenze temporali\n",
        "def prepara_dati(df_cleaned, sequenza_lenght=5):\n",
        "    sequenze = []\n",
        "    target = []\n",
        "\n",
        "    # Cicliamo per creare le sequenze\n",
        "    for i in range(len(df_cleaned) - sequenza_lenght):\n",
        "        sequenza = df_cleaned.iloc[i:i + sequenza_lenght].values.flatten()\n",
        "        sequenze.append(sequenza)\n",
        "        target.append(df_cleaned.iloc[i + sequenza_lenght].values.flatten())\n",
        "\n",
        "    # Convertiamo in array numpy\n",
        "    X = np.array(sequenze)\n",
        "    y = np.array(target)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Prepara i dati per l'allenamento\n",
        "X, y = prepara_dati(df_cleaned)\n",
        "\n",
        "# Mostra la forma di X e y per verificarne la corretta preparazione\n",
        "print(f\"Forma di X: {X.shape}\")\n",
        "print(f\"Forma di y: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_JjqVnmMXXC",
        "outputId": "81a58cff-ad0b-461a-985e-2a8e4cb7ed8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma di X: (35, 25)\n",
            "Forma di y: (35, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quarta Cella: Creazione e allenamento del modello"
      ],
      "metadata": {
        "id": "RkX18yi1XBhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Creazione del modello di rete neurale\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))  # Primo strato\n",
        "model.add(Dense(64, activation='relu'))  # Secondo strato\n",
        "model.add(Dense(y.shape[1], activation='linear'))  # Strato di uscita per predizioni numeriche\n",
        "\n",
        "# Compilazione del modello con una funzione di perdita appropriata per la regressione\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Allenamento del modello\n",
        "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Salviamo il modello allenato per usi futuri\n",
        "model.save(\"/content/lotto_model.h5\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6stSJ2MizJ",
        "outputId": "10a16a2b-9fe5-4ac2-91cd-1a89d875d01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Se X Ã¨ 2D, aggiungiamo una dimensione per le caratteristiche\n",
        "if len(X.shape) == 2:\n",
        "    X = np.expand_dims(X, axis=-1)  # Aggiungiamo una dimensione per le features\n",
        "\n",
        "print(X.shape)  # Ora X dovrebbe essere (n_samples, sequence_length, 1)\n",
        "\n",
        "# Creazione del modello LSTM\n",
        "modello = Sequential()\n",
        "modello.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "modello.add(LSTM(units=50))\n",
        "modello.add(Dense(units=5))  # Predizione di 5 numeri per ogni sequenza\n",
        "\n",
        "# Compilazione del modello\n",
        "modello.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Addestramento del modello\n",
        "modello.fit(X, y, epochs=10, batch_size=32)\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "predizione = modello.predict(X[-1].reshape(1, X.shape[1], X.shape[2]))  # Utilizza l'ultima sequenza per la previsione\n",
        "\n",
        "# Funzione per trasformare la previsione in numeri interi tra 1 e 90\n",
        "def trasforma_predizione(predizione):\n",
        "    predizione_arrotondata = np.round(predizione)  # Arrotonda i valori continui\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Limita i valori tra 1 e 90\n",
        "    return predizione_arrotondata.astype(int)  # Converte in interi\n",
        "\n",
        "# Trasforma la predizione in numeri interi da 1 a 90\n",
        "predizione_interi = trasforma_predizione(predizione)\n",
        "# Se X Ã¨ 2D, aggiungiamo una dimensione per le caratteristiche\n",
        "if len(X.shape) == 2:\n",
        "    X = np.expand_dims(X, axis=-1)  # Aggiungiamo una dimensione per le features\n",
        "\n",
        "print(X.shape)  # Ora X dovrebbe essere (n_samples, sequence_length, 1)\n",
        "\n",
        "# Creazione del modello LSTM\n",
        "modello = Sequential()\n",
        "modello.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "modello.add(LSTM(units=50))\n",
        "modello.add(Dense(units=5))  # Predizione di 5 numeri per ogni sequenza\n",
        "\n",
        "# Compilazione del modello\n",
        "modello.compile(optimizer=Adam(), loss='mean_squared_error')\n",
        "\n",
        "# Addestramento del modello\n",
        "modello.fit(X, y, epochs=10, batch_size=32)\n",
        "\n",
        "# Predizione della prossima estrazione\n",
        "predizione = modello.predict(X[-1].reshape(1, X.shape[1], X.shape[2]))  # Utilizza l'ultima sequenza per la previsione\n",
        "\n",
        "# Funzione per trasformare la previsione in numeri interi tra 1 e 90\n",
        "def trasforma_predizione(predizione):\n",
        "    predizione_arrotondata = np.round(predizione)  # Arrotonda i valori continui\n",
        "    predizione_arrotondata = np.clip(predizione_arrotondata, 1, 90)  # Limita i valori tra 1 e 90\n",
        "    return predizione_arrotondata.astype(int)  # Converte in interi\n",
        "\n",
        "# Trasforma la predizione in numeri interi da 1 a 90\n",
        "predizione_interi = trasforma_predizione(predizione)\n",
        "\n",
        "print(f\"Predizione della prossima estrazione: {predizione_interi}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHtK4zKQN0Ni",
        "outputId": "788397ca-0b8e-42e0-85eb-de1fab93f226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35, 25, 1)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan\n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: nan \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79a9e5ae6fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "(35, 25, 1)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-eb2057967d88>:26: RuntimeWarning: invalid value encountered in cast\n",
            "  return predizione_arrotondata.astype(int)  # Converte in interi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: nan \n",
            "Epoch 4/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan \n",
            "Epoch 5/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: nan \n",
            "Epoch 7/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "\u001b[1m2/2\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79a9edacab60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step\n",
            "Predizione della prossima estrazione: [[-9223372036854775808 -9223372036854775808 -9223372036854775808\n",
            "  -9223372036854775808 -9223372036854775808]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-eb2057967d88>:55: RuntimeWarning: invalid value encountered in cast\n",
            "  return predizione_arrotondata.astype(int)  # Converte in interi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quinta Cella: Fare previsioni"
      ],
      "metadata": {
        "id": "29NF5kYVXNf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "noooo"
      ],
      "metadata": {
        "id": "B2aWE5ZSXW28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "next step"
      ],
      "metadata": {
        "id": "ti2A1-cGXij5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Genera una previsione (esempio semplificato)\n",
        "# La previsione si basa sui numeri piÃ¹ frequenti\n",
        "previsione = numeri_frequenti"
      ],
      "metadata": {
        "id": "R8LasAQU3aS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "a4959add-5777-4ba4-d9eb-f45cdf30d947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'numeri_frequenti' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-318e02fd9b0f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Genera una previsione (esempio semplificato)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# La previsione si basa sui numeri piÃ¹ frequenti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprevisione\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeri_frequenti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'numeri_frequenti' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un DataFrame per la previsione\n",
        "previsione_df = pd.DataFrame({'Numero': previsione})\n"
      ],
      "metadata": {
        "id": "_hMO6Nnx3dKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva la previsione in un file CSV\n",
        "previsione_df.to_csv('/content/previsione_lotto.csv', index=False)\n",
        "\n",
        "print(\"Previsione salvata in /content/previsione_lotto.csv\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/previsione_lotto.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gimKnDF-3gD1",
        "outputId": "e859db19-4ec3-446e-9f34-876731daf8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previsione salvata in /content/previsione_lotto.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_db4c86d1-f896-4b35-b8f0-c4c98b3cb7f7\", \"previsione_lotto.csv\", 30)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Un benvenuto a Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}